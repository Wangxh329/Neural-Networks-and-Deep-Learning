{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqB54J4_um3H"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, ELU, Flatten, MaxPool2D\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.initializers import lecun_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n5sAg_FAum3L"
   },
   "source": [
    "## Dataset\n",
    "We only use the first 22 eeg features, and transfer labels from 769-772 to 0-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0Z-SMj3um3M"
   },
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "X_train_valid = X_train_valid[:, :22, :]\n",
    "X_test = X_test[:, :22, :]\n",
    "y_train_valid = to_categorical(y_train_valid - 769)\n",
    "y_test = to_categorical(y_test - 769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvfes_qOum3P"
   },
   "source": [
    "## Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "PT3cBNNCum3P",
    "outputId": "e31f7b9f-a985-4f08-bb6a-faff2ccb1b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115, 4)\n",
      "Test target shape: (443, 4)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ulir-BwKum3Z"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHBrvlK0GhGH"
   },
   "source": [
    "CNN model for dataset over time period [100, 450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kwl4P8NUum3Z"
   },
   "outputs": [],
   "source": [
    "def cnn_model_smaller_than_450(time_period=450):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=(1, 5), strides=1, padding='valid', kernel_regularizer=L1L2(l1=0, l2=0.01), input_shape=(22, time_period, 1), data_format='channels_last'))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D((1, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(1, 5), strides=1, padding='valid', kernel_regularizer=L1L2(l1=0, l2=0.01)))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D((1, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(1, 5), strides=1, padding='valid', kernel_regularizer=L1L2(l1=0, l2=0.01)))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D((1, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, kernel_regularizer=L1L2(l1=0, l2=0.01), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001, epsilon=1e-8, decay=0.01), metrics=[categorical_accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM36BT2oHI6a"
   },
   "source": [
    "CNN model for dataset over time period >= 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wHokK5_HJ7N"
   },
   "outputs": [],
   "source": [
    "def cnn_model(time_period=1000):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=(1, 10), strides=1, padding='valid', kernel_regularizer=L1L2(l1=0, l2=0.01), input_shape=(22, time_period, 1), data_format='channels_last'))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D((1, 4)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(1, 10), strides=1, padding='valid', kernel_regularizer=L1L2(l1=0, l2=0.01)))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D((1, 4)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(1, 10), strides=1, padding='valid', kernel_regularizer=L1L2(l1=0, l2=0.01)))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D((1, 4)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(21, 1), strides=1, padding='valid', kernel_regularizer=L1L2(l1=0, l2=0.01)))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D((1, 4)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, kernel_regularizer=L1L2(l1=0, l2=0.01), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001, epsilon=1e-8, decay=0.01), metrics=[categorical_accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24uY_TqCum3c"
   },
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEAp9nxlum3d"
   },
   "outputs": [],
   "source": [
    "def train_data(time_period=1000):\n",
    "    # different period of time\n",
    "    X_train_valid_cur = X_train_valid[:, :, :time_period]\n",
    "    y_train_valid_cur = y_train_valid\n",
    "    X_test_cur = X_test[:, :, :time_period]\n",
    "    y_test_cur = y_test\n",
    "\n",
    "    # preprocess data\n",
    "    X_train_valid_cur = np.expand_dims(X_train_valid_cur, axis=3)\n",
    "    X_test_cur = np.expand_dims(X_test_cur, axis=3)\n",
    "    lecun = lecun_uniform(seed=42)\n",
    "    \n",
    "    if time_period < 450:\n",
    "        model = cnn_model_smaller_than_450(time_period)\n",
    "    else:\n",
    "        model = cnn_model(time_period)\n",
    "    model.fit(X_train_valid_cur, y_train_valid_cur, epochs=40, batch_size=32, validation_data=(X_test_cur, y_test_cur), shuffle=True, verbose=1)\n",
    "    train_score = model.evaluate(X_train_valid_cur, y_train_valid_cur)\n",
    "    test_score = model.evaluate(X_test_cur, y_test_cur)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    print(model.summary())\n",
    "    \n",
    "    return train_score, test_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d8EUvUArGFNT"
   },
   "source": [
    "##All Subjects over Time = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2519
    },
    "colab_type": "code",
    "id": "vWGCy_NbGIE1",
    "outputId": "1006ff6a-7ffa-4129-c25c-be00b2ae20c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 3.4535 - categorical_accuracy: 0.2742 - val_loss: 3.1801 - val_categorical_accuracy: 0.3025\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.8705 - categorical_accuracy: 0.2582 - val_loss: 2.6344 - val_categorical_accuracy: 0.2822\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.6415 - categorical_accuracy: 0.3102 - val_loss: 2.4451 - val_categorical_accuracy: 0.3025\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.4685 - categorical_accuracy: 0.3395 - val_loss: 2.3093 - val_categorical_accuracy: 0.3589\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.3469 - categorical_accuracy: 0.3650 - val_loss: 2.2022 - val_categorical_accuracy: 0.3995\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.2250 - categorical_accuracy: 0.4033 - val_loss: 2.1466 - val_categorical_accuracy: 0.3883\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.1497 - categorical_accuracy: 0.4080 - val_loss: 2.0593 - val_categorical_accuracy: 0.4492\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.0466 - categorical_accuracy: 0.4463 - val_loss: 2.0183 - val_categorical_accuracy: 0.4537\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.9683 - categorical_accuracy: 0.4742 - val_loss: 1.9600 - val_categorical_accuracy: 0.4515\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.9164 - categorical_accuracy: 0.4941 - val_loss: 1.9179 - val_categorical_accuracy: 0.4898\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.8314 - categorical_accuracy: 0.5310 - val_loss: 1.8872 - val_categorical_accuracy: 0.5011\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.7926 - categorical_accuracy: 0.5357 - val_loss: 1.8672 - val_categorical_accuracy: 0.4831\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.7182 - categorical_accuracy: 0.5598 - val_loss: 1.8159 - val_categorical_accuracy: 0.5260\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.7070 - categorical_accuracy: 0.5612 - val_loss: 1.8098 - val_categorical_accuracy: 0.5169\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.6491 - categorical_accuracy: 0.5995 - val_loss: 1.8059 - val_categorical_accuracy: 0.4853\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.6200 - categorical_accuracy: 0.5962 - val_loss: 1.7633 - val_categorical_accuracy: 0.5169\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5746 - categorical_accuracy: 0.6132 - val_loss: 1.7522 - val_categorical_accuracy: 0.5214\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5554 - categorical_accuracy: 0.6241 - val_loss: 1.7648 - val_categorical_accuracy: 0.4989\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5142 - categorical_accuracy: 0.6426 - val_loss: 1.7404 - val_categorical_accuracy: 0.5305\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4984 - categorical_accuracy: 0.6383 - val_loss: 1.7271 - val_categorical_accuracy: 0.5350\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4965 - categorical_accuracy: 0.6430 - val_loss: 1.7172 - val_categorical_accuracy: 0.5350\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4947 - categorical_accuracy: 0.6378 - val_loss: 1.6964 - val_categorical_accuracy: 0.5598\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4306 - categorical_accuracy: 0.6600 - val_loss: 1.7035 - val_categorical_accuracy: 0.5305\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3675 - categorical_accuracy: 0.6917 - val_loss: 1.6916 - val_categorical_accuracy: 0.5372\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3989 - categorical_accuracy: 0.6832 - val_loss: 1.7065 - val_categorical_accuracy: 0.5395\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3948 - categorical_accuracy: 0.6752 - val_loss: 1.6848 - val_categorical_accuracy: 0.5440\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3458 - categorical_accuracy: 0.6974 - val_loss: 1.6871 - val_categorical_accuracy: 0.5372\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3258 - categorical_accuracy: 0.7026 - val_loss: 1.7284 - val_categorical_accuracy: 0.4921\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3095 - categorical_accuracy: 0.7111 - val_loss: 1.6760 - val_categorical_accuracy: 0.5282\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3012 - categorical_accuracy: 0.7087 - val_loss: 1.6854 - val_categorical_accuracy: 0.5350\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2914 - categorical_accuracy: 0.7125 - val_loss: 1.6666 - val_categorical_accuracy: 0.5485\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2777 - categorical_accuracy: 0.7168 - val_loss: 1.6699 - val_categorical_accuracy: 0.5327\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2509 - categorical_accuracy: 0.7234 - val_loss: 1.7135 - val_categorical_accuracy: 0.5327\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2704 - categorical_accuracy: 0.7154 - val_loss: 1.6705 - val_categorical_accuracy: 0.5440\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2518 - categorical_accuracy: 0.7201 - val_loss: 1.6824 - val_categorical_accuracy: 0.5350\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2061 - categorical_accuracy: 0.7414 - val_loss: 1.6819 - val_categorical_accuracy: 0.5395\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2117 - categorical_accuracy: 0.7333 - val_loss: 1.6696 - val_categorical_accuracy: 0.5418\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.1721 - categorical_accuracy: 0.7513 - val_loss: 1.6885 - val_categorical_accuracy: 0.5418\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2124 - categorical_accuracy: 0.7357 - val_loss: 1.6644 - val_categorical_accuracy: 0.5395\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.1612 - categorical_accuracy: 0.7574 - val_loss: 1.6993 - val_categorical_accuracy: 0.5395\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 0.9812 - categorical_accuracy: 0.8671\n",
      "443/443 [==============================] - 0s 1ms/sample - loss: 1.6993 - categorical_accuracy: 0.5395\n",
      "train categorical_accuracy: 86.714%\n",
      "test categorical_accuracy: 53.950%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 22, 991, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu (ELU)                    (None, 22, 991, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 22, 991, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 247, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 247, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 238, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 22, 238, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 22, 238, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 50, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 22, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 22, 50, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 22, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 12, 128)        172160    \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 2, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 2, 12, 128)        8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 3076      \n",
      "=================================================================\n",
      "Total params: 201,380\n",
      "Trainable params: 201,244\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_score, test_score = train_data(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9IoRrMQF-YR"
   },
   "source": [
    "##Function of Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 43868
    },
    "colab_type": "code",
    "id": "s3KA3EFTGA6C",
    "outputId": "935537e0-b56b-489f-d1eb-deaa238bedda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================100===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.9847 - categorical_accuracy: 0.3149 - val_loss: 2.4800 - val_categorical_accuracy: 0.3589\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.2381 - categorical_accuracy: 0.3882 - val_loss: 2.2635 - val_categorical_accuracy: 0.3837\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.1269 - categorical_accuracy: 0.4080 - val_loss: 2.1461 - val_categorical_accuracy: 0.3860\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 2s 854us/sample - loss: 2.0193 - categorical_accuracy: 0.4374 - val_loss: 1.9808 - val_categorical_accuracy: 0.3973\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 1s 571us/sample - loss: 1.9940 - categorical_accuracy: 0.4572 - val_loss: 1.8951 - val_categorical_accuracy: 0.4289\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 1s 563us/sample - loss: 1.8777 - categorical_accuracy: 0.4771 - val_loss: 1.8756 - val_categorical_accuracy: 0.4402\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 1s 540us/sample - loss: 1.8347 - categorical_accuracy: 0.4903 - val_loss: 1.8656 - val_categorical_accuracy: 0.4334\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 1s 550us/sample - loss: 1.8263 - categorical_accuracy: 0.4861 - val_loss: 1.8660 - val_categorical_accuracy: 0.4289\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 1s 566us/sample - loss: 1.7791 - categorical_accuracy: 0.4979 - val_loss: 1.8596 - val_categorical_accuracy: 0.4379\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 1s 568us/sample - loss: 1.7680 - categorical_accuracy: 0.5177 - val_loss: 1.8260 - val_categorical_accuracy: 0.4492\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 1s 576us/sample - loss: 1.7090 - categorical_accuracy: 0.5428 - val_loss: 1.8164 - val_categorical_accuracy: 0.4470\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 1s 535us/sample - loss: 1.7009 - categorical_accuracy: 0.5267 - val_loss: 1.7984 - val_categorical_accuracy: 0.4537\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 1s 555us/sample - loss: 1.6622 - categorical_accuracy: 0.5617 - val_loss: 1.8066 - val_categorical_accuracy: 0.4334\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 1s 536us/sample - loss: 1.6660 - categorical_accuracy: 0.5409 - val_loss: 1.8535 - val_categorical_accuracy: 0.4221\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 1s 550us/sample - loss: 1.6667 - categorical_accuracy: 0.5395 - val_loss: 1.7826 - val_categorical_accuracy: 0.4424\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 1s 544us/sample - loss: 1.6227 - categorical_accuracy: 0.5584 - val_loss: 1.7759 - val_categorical_accuracy: 0.4334\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 1s 542us/sample - loss: 1.6391 - categorical_accuracy: 0.5546 - val_loss: 1.8054 - val_categorical_accuracy: 0.4221\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 1s 533us/sample - loss: 1.5976 - categorical_accuracy: 0.5735 - val_loss: 1.8009 - val_categorical_accuracy: 0.4402\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 1s 559us/sample - loss: 1.5796 - categorical_accuracy: 0.5735 - val_loss: 1.8063 - val_categorical_accuracy: 0.4357\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 1s 558us/sample - loss: 1.5796 - categorical_accuracy: 0.5801 - val_loss: 1.7686 - val_categorical_accuracy: 0.4289\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 2s 786us/sample - loss: 1.5794 - categorical_accuracy: 0.5726 - val_loss: 1.7652 - val_categorical_accuracy: 0.4560\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 1s 643us/sample - loss: 1.5465 - categorical_accuracy: 0.5844 - val_loss: 1.7837 - val_categorical_accuracy: 0.4334\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5293 - categorical_accuracy: 0.5901 - val_loss: 1.7871 - val_categorical_accuracy: 0.4402\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5285 - categorical_accuracy: 0.5929 - val_loss: 1.7715 - val_categorical_accuracy: 0.4334\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5087 - categorical_accuracy: 0.5882 - val_loss: 1.7771 - val_categorical_accuracy: 0.4266\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5059 - categorical_accuracy: 0.6000 - val_loss: 1.7567 - val_categorical_accuracy: 0.4379\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4879 - categorical_accuracy: 0.6043 - val_loss: 1.7709 - val_categorical_accuracy: 0.4289\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4717 - categorical_accuracy: 0.6033 - val_loss: 1.7744 - val_categorical_accuracy: 0.4447\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4696 - categorical_accuracy: 0.5991 - val_loss: 1.7581 - val_categorical_accuracy: 0.4244\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4515 - categorical_accuracy: 0.6095 - val_loss: 1.7447 - val_categorical_accuracy: 0.4334\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4452 - categorical_accuracy: 0.6147 - val_loss: 1.7639 - val_categorical_accuracy: 0.4379\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4378 - categorical_accuracy: 0.6312 - val_loss: 1.7448 - val_categorical_accuracy: 0.4515\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4375 - categorical_accuracy: 0.6312 - val_loss: 1.7590 - val_categorical_accuracy: 0.4447\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4475 - categorical_accuracy: 0.6222 - val_loss: 1.7497 - val_categorical_accuracy: 0.4492\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4175 - categorical_accuracy: 0.6184 - val_loss: 1.7534 - val_categorical_accuracy: 0.4447\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4106 - categorical_accuracy: 0.6392 - val_loss: 1.7794 - val_categorical_accuracy: 0.4447\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4152 - categorical_accuracy: 0.6251 - val_loss: 1.7535 - val_categorical_accuracy: 0.4334\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4010 - categorical_accuracy: 0.6175 - val_loss: 1.7554 - val_categorical_accuracy: 0.4402\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 2s 959us/sample - loss: 1.4188 - categorical_accuracy: 0.6331 - val_loss: 1.7581 - val_categorical_accuracy: 0.4515\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 1s 549us/sample - loss: 1.3813 - categorical_accuracy: 0.6548 - val_loss: 1.7648 - val_categorical_accuracy: 0.4560\n",
      "2115/2115 [==============================] - 0s 181us/sample - loss: 1.1998 - categorical_accuracy: 0.7527\n",
      "443/443 [==============================] - 0s 171us/sample - loss: 1.7648 - categorical_accuracy: 0.4560\n",
      "train categorical_accuracy: 75.272%\n",
      "test categorical_accuracy: 45.598%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 22, 96, 16)        96        \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 22, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 22, 96, 16)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 22, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 22, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 22, 44, 32)        2592      \n",
      "_________________________________________________________________\n",
      "elu_5 (ELU)                  (None, 22, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 22, 44, 32)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 22, 18, 64)        10304     \n",
      "_________________________________________________________________\n",
      "elu_6 (ELU)                  (None, 22, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 22, 18, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 22, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 22, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12672)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 50692     \n",
      "=================================================================\n",
      "Total params: 63,948\n",
      "Trainable params: 63,816\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================150===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 3.4256 - categorical_accuracy: 0.3277 - val_loss: 2.6479 - val_categorical_accuracy: 0.3725\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 1s 705us/sample - loss: 2.3652 - categorical_accuracy: 0.4071 - val_loss: 2.2663 - val_categorical_accuracy: 0.4108\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 1s 706us/sample - loss: 2.1147 - categorical_accuracy: 0.4577 - val_loss: 2.1258 - val_categorical_accuracy: 0.4266\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 2s 718us/sample - loss: 2.0015 - categorical_accuracy: 0.4714 - val_loss: 1.9845 - val_categorical_accuracy: 0.4808\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 1s 697us/sample - loss: 1.9490 - categorical_accuracy: 0.4998 - val_loss: 1.9648 - val_categorical_accuracy: 0.4786\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 1s 700us/sample - loss: 1.8487 - categorical_accuracy: 0.5229 - val_loss: 1.9736 - val_categorical_accuracy: 0.4176\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 1s 691us/sample - loss: 1.8073 - categorical_accuracy: 0.5433 - val_loss: 1.9527 - val_categorical_accuracy: 0.4763\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 1s 684us/sample - loss: 1.7696 - categorical_accuracy: 0.5508 - val_loss: 1.9582 - val_categorical_accuracy: 0.4492\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 2s 925us/sample - loss: 1.7520 - categorical_accuracy: 0.5504 - val_loss: 1.8634 - val_categorical_accuracy: 0.4876\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 2s 997us/sample - loss: 1.7032 - categorical_accuracy: 0.5707 - val_loss: 1.8740 - val_categorical_accuracy: 0.4898\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6655 - categorical_accuracy: 0.5801 - val_loss: 1.9213 - val_categorical_accuracy: 0.4537\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6239 - categorical_accuracy: 0.5981 - val_loss: 1.8275 - val_categorical_accuracy: 0.4944\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5864 - categorical_accuracy: 0.6147 - val_loss: 1.8219 - val_categorical_accuracy: 0.4944\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5817 - categorical_accuracy: 0.6080 - val_loss: 1.8223 - val_categorical_accuracy: 0.4876\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5583 - categorical_accuracy: 0.6142 - val_loss: 1.8254 - val_categorical_accuracy: 0.4763\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5461 - categorical_accuracy: 0.6147 - val_loss: 1.8366 - val_categorical_accuracy: 0.4921\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5333 - categorical_accuracy: 0.6217 - val_loss: 1.8285 - val_categorical_accuracy: 0.5079\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4991 - categorical_accuracy: 0.6378 - val_loss: 1.8183 - val_categorical_accuracy: 0.5124\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4968 - categorical_accuracy: 0.6459 - val_loss: 1.8301 - val_categorical_accuracy: 0.4921\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4624 - categorical_accuracy: 0.6487 - val_loss: 1.8195 - val_categorical_accuracy: 0.4808\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4676 - categorical_accuracy: 0.6388 - val_loss: 1.8359 - val_categorical_accuracy: 0.4989\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4052 - categorical_accuracy: 0.6709 - val_loss: 1.8529 - val_categorical_accuracy: 0.4831\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4443 - categorical_accuracy: 0.6563 - val_loss: 1.8111 - val_categorical_accuracy: 0.5034\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4244 - categorical_accuracy: 0.6733 - val_loss: 1.8233 - val_categorical_accuracy: 0.4876\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 2s 720us/sample - loss: 1.3846 - categorical_accuracy: 0.6700 - val_loss: 1.8277 - val_categorical_accuracy: 0.4898\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 2s 711us/sample - loss: 1.3782 - categorical_accuracy: 0.6842 - val_loss: 1.8192 - val_categorical_accuracy: 0.4921\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 1s 706us/sample - loss: 1.3700 - categorical_accuracy: 0.6898 - val_loss: 1.8148 - val_categorical_accuracy: 0.4853\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 1s 699us/sample - loss: 1.3610 - categorical_accuracy: 0.6922 - val_loss: 1.8308 - val_categorical_accuracy: 0.4898\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 2s 719us/sample - loss: 1.3582 - categorical_accuracy: 0.6846 - val_loss: 1.8356 - val_categorical_accuracy: 0.4786\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 1s 690us/sample - loss: 1.3101 - categorical_accuracy: 0.7144 - val_loss: 1.8172 - val_categorical_accuracy: 0.4921\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 1s 709us/sample - loss: 1.3333 - categorical_accuracy: 0.6879 - val_loss: 1.8335 - val_categorical_accuracy: 0.4876\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 1s 701us/sample - loss: 1.3200 - categorical_accuracy: 0.6983 - val_loss: 1.8232 - val_categorical_accuracy: 0.4966\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 1s 675us/sample - loss: 1.2774 - categorical_accuracy: 0.7277 - val_loss: 1.8314 - val_categorical_accuracy: 0.4966\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 1s 681us/sample - loss: 1.3105 - categorical_accuracy: 0.6983 - val_loss: 1.8329 - val_categorical_accuracy: 0.5056\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 1s 690us/sample - loss: 1.3028 - categorical_accuracy: 0.7106 - val_loss: 1.8386 - val_categorical_accuracy: 0.4853\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 1s 699us/sample - loss: 1.2709 - categorical_accuracy: 0.7182 - val_loss: 1.8457 - val_categorical_accuracy: 0.4831\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 2s 730us/sample - loss: 1.2762 - categorical_accuracy: 0.7069 - val_loss: 1.8649 - val_categorical_accuracy: 0.4673\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 1s 683us/sample - loss: 1.2720 - categorical_accuracy: 0.7296 - val_loss: 1.8557 - val_categorical_accuracy: 0.4921\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 1s 677us/sample - loss: 1.2627 - categorical_accuracy: 0.7144 - val_loss: 1.8530 - val_categorical_accuracy: 0.4718\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 2s 825us/sample - loss: 1.2553 - categorical_accuracy: 0.7333 - val_loss: 1.8525 - val_categorical_accuracy: 0.4966\n",
      "2115/2115 [==============================] - 1s 366us/sample - loss: 1.0303 - categorical_accuracy: 0.8534\n",
      "443/443 [==============================] - 0s 225us/sample - loss: 1.8525 - categorical_accuracy: 0.4966\n",
      "train categorical_accuracy: 85.343%\n",
      "test categorical_accuracy: 49.661%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 22, 146, 16)       96        \n",
      "_________________________________________________________________\n",
      "elu_7 (ELU)                  (None, 22, 146, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 22, 146, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 22, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 22, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 69, 32)        2592      \n",
      "_________________________________________________________________\n",
      "elu_8 (ELU)                  (None, 22, 69, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 22, 69, 32)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 22, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 22, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 22, 30, 64)        10304     \n",
      "_________________________________________________________________\n",
      "elu_9 (ELU)                  (None, 22, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 22, 30, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 22, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 22, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 21120)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 84484     \n",
      "=================================================================\n",
      "Total params: 97,740\n",
      "Trainable params: 97,608\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================200===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 5.2540 - categorical_accuracy: 0.3139 - val_loss: 2.9717 - val_categorical_accuracy: 0.3589\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.6464 - categorical_accuracy: 0.4227 - val_loss: 2.4415 - val_categorical_accuracy: 0.3679\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.1716 - categorical_accuracy: 0.4922 - val_loss: 2.1673 - val_categorical_accuracy: 0.4447\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.9928 - categorical_accuracy: 0.5348 - val_loss: 2.1564 - val_categorical_accuracy: 0.4289\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.9091 - categorical_accuracy: 0.5560 - val_loss: 2.1165 - val_categorical_accuracy: 0.4357\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.8236 - categorical_accuracy: 0.5650 - val_loss: 2.0176 - val_categorical_accuracy: 0.4605\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.7358 - categorical_accuracy: 0.6038 - val_loss: 1.9919 - val_categorical_accuracy: 0.4740\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.6912 - categorical_accuracy: 0.6085 - val_loss: 2.0093 - val_categorical_accuracy: 0.4763\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.6028 - categorical_accuracy: 0.6364 - val_loss: 2.0103 - val_categorical_accuracy: 0.4560\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.6042 - categorical_accuracy: 0.6378 - val_loss: 2.0146 - val_categorical_accuracy: 0.4831\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5676 - categorical_accuracy: 0.6544 - val_loss: 2.0146 - val_categorical_accuracy: 0.4831\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 2s 850us/sample - loss: 1.5109 - categorical_accuracy: 0.6728 - val_loss: 1.9990 - val_categorical_accuracy: 0.4853\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 2s 875us/sample - loss: 1.5189 - categorical_accuracy: 0.6473 - val_loss: 2.0347 - val_categorical_accuracy: 0.4740\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 2s 877us/sample - loss: 1.5013 - categorical_accuracy: 0.6671 - val_loss: 1.9864 - val_categorical_accuracy: 0.4876\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 2s 859us/sample - loss: 1.4691 - categorical_accuracy: 0.6804 - val_loss: 2.0030 - val_categorical_accuracy: 0.4740\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 2s 860us/sample - loss: 1.4443 - categorical_accuracy: 0.6875 - val_loss: 1.9734 - val_categorical_accuracy: 0.4831\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 2s 850us/sample - loss: 1.4394 - categorical_accuracy: 0.6842 - val_loss: 2.0016 - val_categorical_accuracy: 0.4989\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 2s 819us/sample - loss: 1.4058 - categorical_accuracy: 0.6960 - val_loss: 1.9597 - val_categorical_accuracy: 0.4966\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 2s 852us/sample - loss: 1.4246 - categorical_accuracy: 0.7054 - val_loss: 1.9893 - val_categorical_accuracy: 0.4763\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 2s 880us/sample - loss: 1.3629 - categorical_accuracy: 0.7196 - val_loss: 1.9660 - val_categorical_accuracy: 0.4921\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 2s 833us/sample - loss: 1.3417 - categorical_accuracy: 0.7168 - val_loss: 1.9776 - val_categorical_accuracy: 0.4966\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 2s 854us/sample - loss: 1.3430 - categorical_accuracy: 0.7357 - val_loss: 1.9914 - val_categorical_accuracy: 0.4989\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 2s 855us/sample - loss: 1.3270 - categorical_accuracy: 0.7324 - val_loss: 1.9958 - val_categorical_accuracy: 0.4786\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 2s 837us/sample - loss: 1.3038 - categorical_accuracy: 0.7319 - val_loss: 1.9994 - val_categorical_accuracy: 0.5011\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3047 - categorical_accuracy: 0.7433 - val_loss: 1.9943 - val_categorical_accuracy: 0.4853\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2726 - categorical_accuracy: 0.7565 - val_loss: 2.0048 - val_categorical_accuracy: 0.4763\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.2547 - categorical_accuracy: 0.7603 - val_loss: 2.0220 - val_categorical_accuracy: 0.4876\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.2598 - categorical_accuracy: 0.7546 - val_loss: 2.0239 - val_categorical_accuracy: 0.4966\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.2697 - categorical_accuracy: 0.7485 - val_loss: 2.0549 - val_categorical_accuracy: 0.4853\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.2481 - categorical_accuracy: 0.7570 - val_loss: 2.0273 - val_categorical_accuracy: 0.4718\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.2053 - categorical_accuracy: 0.7811 - val_loss: 2.0537 - val_categorical_accuracy: 0.4763\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.2118 - categorical_accuracy: 0.7707 - val_loss: 2.0684 - val_categorical_accuracy: 0.4853\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.2299 - categorical_accuracy: 0.7641 - val_loss: 2.0287 - val_categorical_accuracy: 0.4921\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.1983 - categorical_accuracy: 0.7797 - val_loss: 2.0286 - val_categorical_accuracy: 0.4831\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.1868 - categorical_accuracy: 0.7835 - val_loss: 2.0224 - val_categorical_accuracy: 0.4808\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.1753 - categorical_accuracy: 0.7849 - val_loss: 2.0463 - val_categorical_accuracy: 0.4740\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.1760 - categorical_accuracy: 0.7934 - val_loss: 2.0150 - val_categorical_accuracy: 0.4898\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.1704 - categorical_accuracy: 0.7820 - val_loss: 2.0398 - val_categorical_accuracy: 0.4966\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1493 - categorical_accuracy: 0.7991 - val_loss: 2.0374 - val_categorical_accuracy: 0.4831\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 2s 839us/sample - loss: 1.1390 - categorical_accuracy: 0.8047 - val_loss: 2.0456 - val_categorical_accuracy: 0.4650\n",
      "2115/2115 [==============================] - 1s 272us/sample - loss: 0.9143 - categorical_accuracy: 0.9376\n",
      "443/443 [==============================] - 0s 284us/sample - loss: 2.0456 - categorical_accuracy: 0.4650\n",
      "train categorical_accuracy: 93.759%\n",
      "test categorical_accuracy: 46.501%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 22, 196, 16)       96        \n",
      "_________________________________________________________________\n",
      "elu_10 (ELU)                 (None, 22, 196, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 22, 196, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 22, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 22, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 22, 94, 32)        2592      \n",
      "_________________________________________________________________\n",
      "elu_11 (ELU)                 (None, 22, 94, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 22, 94, 32)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 22, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 22, 43, 64)        10304     \n",
      "_________________________________________________________________\n",
      "elu_12 (ELU)                 (None, 22, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 22, 43, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 22, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 22, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 29568)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 118276    \n",
      "=================================================================\n",
      "Total params: 131,532\n",
      "Trainable params: 131,400\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================250===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 4.3034 - categorical_accuracy: 0.3130 - val_loss: 2.5818 - val_categorical_accuracy: 0.4199\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 2s 996us/sample - loss: 2.4827 - categorical_accuracy: 0.4430 - val_loss: 2.4574 - val_categorical_accuracy: 0.3950\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.0477 - categorical_accuracy: 0.5371 - val_loss: 2.1620 - val_categorical_accuracy: 0.4266\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.8748 - categorical_accuracy: 0.5678 - val_loss: 2.1571 - val_categorical_accuracy: 0.4650\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 2s 994us/sample - loss: 1.7844 - categorical_accuracy: 0.5957 - val_loss: 2.1292 - val_categorical_accuracy: 0.4470\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7287 - categorical_accuracy: 0.6109 - val_loss: 2.0485 - val_categorical_accuracy: 0.4470\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6313 - categorical_accuracy: 0.6279 - val_loss: 2.0402 - val_categorical_accuracy: 0.4560\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5607 - categorical_accuracy: 0.6652 - val_loss: 2.0746 - val_categorical_accuracy: 0.4470\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.5237 - categorical_accuracy: 0.6846 - val_loss: 2.0578 - val_categorical_accuracy: 0.4763\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.4709 - categorical_accuracy: 0.7021 - val_loss: 2.1029 - val_categorical_accuracy: 0.4424\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.4106 - categorical_accuracy: 0.7229 - val_loss: 2.1054 - val_categorical_accuracy: 0.4560\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.3993 - categorical_accuracy: 0.7210 - val_loss: 2.0989 - val_categorical_accuracy: 0.4628\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.3094 - categorical_accuracy: 0.7612 - val_loss: 2.0914 - val_categorical_accuracy: 0.4628\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.3158 - categorical_accuracy: 0.7480 - val_loss: 2.1010 - val_categorical_accuracy: 0.4786\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2603 - categorical_accuracy: 0.7735 - val_loss: 2.1116 - val_categorical_accuracy: 0.4650\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2604 - categorical_accuracy: 0.7716 - val_loss: 2.1776 - val_categorical_accuracy: 0.4470\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2220 - categorical_accuracy: 0.7957 - val_loss: 2.1793 - val_categorical_accuracy: 0.4379\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2084 - categorical_accuracy: 0.7929 - val_loss: 2.2553 - val_categorical_accuracy: 0.4402\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.1963 - categorical_accuracy: 0.7957 - val_loss: 2.2212 - val_categorical_accuracy: 0.4357\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1894 - categorical_accuracy: 0.7905 - val_loss: 2.2723 - val_categorical_accuracy: 0.4402\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1537 - categorical_accuracy: 0.7967 - val_loss: 2.2859 - val_categorical_accuracy: 0.4650\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1302 - categorical_accuracy: 0.8184 - val_loss: 2.2325 - val_categorical_accuracy: 0.4402\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1209 - categorical_accuracy: 0.8232 - val_loss: 2.2812 - val_categorical_accuracy: 0.4515\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1070 - categorical_accuracy: 0.8194 - val_loss: 2.3060 - val_categorical_accuracy: 0.4357\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0749 - categorical_accuracy: 0.8336 - val_loss: 2.3238 - val_categorical_accuracy: 0.4447\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0737 - categorical_accuracy: 0.8293 - val_loss: 2.3517 - val_categorical_accuracy: 0.4537\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0792 - categorical_accuracy: 0.8374 - val_loss: 2.3222 - val_categorical_accuracy: 0.4424\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0745 - categorical_accuracy: 0.8317 - val_loss: 2.3226 - val_categorical_accuracy: 0.4628\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0465 - categorical_accuracy: 0.8421 - val_loss: 2.3746 - val_categorical_accuracy: 0.4447\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0252 - categorical_accuracy: 0.8572 - val_loss: 2.3091 - val_categorical_accuracy: 0.4470\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0253 - categorical_accuracy: 0.8515 - val_loss: 2.3732 - val_categorical_accuracy: 0.4515\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0180 - categorical_accuracy: 0.8652 - val_loss: 2.3552 - val_categorical_accuracy: 0.4447\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0183 - categorical_accuracy: 0.8586 - val_loss: 2.4025 - val_categorical_accuracy: 0.4266\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9797 - categorical_accuracy: 0.8761 - val_loss: 2.3996 - val_categorical_accuracy: 0.4334\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9906 - categorical_accuracy: 0.8667 - val_loss: 2.3815 - val_categorical_accuracy: 0.4402\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9710 - categorical_accuracy: 0.8747 - val_loss: 2.4128 - val_categorical_accuracy: 0.4334\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9648 - categorical_accuracy: 0.8775 - val_loss: 2.3832 - val_categorical_accuracy: 0.4447\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9734 - categorical_accuracy: 0.8742 - val_loss: 2.4072 - val_categorical_accuracy: 0.4244\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9568 - categorical_accuracy: 0.8804 - val_loss: 2.4472 - val_categorical_accuracy: 0.4289\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9728 - categorical_accuracy: 0.8733 - val_loss: 2.4311 - val_categorical_accuracy: 0.4447\n",
      "2115/2115 [==============================] - 1s 517us/sample - loss: 0.7597 - categorical_accuracy: 0.9839\n",
      "443/443 [==============================] - 0s 539us/sample - loss: 2.4311 - categorical_accuracy: 0.4447\n",
      "train categorical_accuracy: 98.392%\n",
      "test categorical_accuracy: 44.470%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 22, 246, 16)       96        \n",
      "_________________________________________________________________\n",
      "elu_13 (ELU)                 (None, 22, 246, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 22, 246, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 22, 123, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 22, 123, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 22, 119, 32)       2592      \n",
      "_________________________________________________________________\n",
      "elu_14 (ELU)                 (None, 22, 119, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 22, 119, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 22, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 22, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 22, 55, 64)        10304     \n",
      "_________________________________________________________________\n",
      "elu_15 (ELU)                 (None, 22, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 22, 55, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 22, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 22, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 38016)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 152068    \n",
      "=================================================================\n",
      "Total params: 165,324\n",
      "Trainable params: 165,192\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================300===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 8.0503 - categorical_accuracy: 0.2809 - val_loss: 5.8889 - val_categorical_accuracy: 0.3544\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 3.3601 - categorical_accuracy: 0.4085 - val_loss: 3.5167 - val_categorical_accuracy: 0.3567\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.4054 - categorical_accuracy: 0.4865 - val_loss: 2.4609 - val_categorical_accuracy: 0.4402\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.0412 - categorical_accuracy: 0.5385 - val_loss: 2.3165 - val_categorical_accuracy: 0.4605\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.9950 - categorical_accuracy: 0.5603 - val_loss: 2.2509 - val_categorical_accuracy: 0.4628\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.8144 - categorical_accuracy: 0.5939 - val_loss: 2.2406 - val_categorical_accuracy: 0.4605\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7479 - categorical_accuracy: 0.6175 - val_loss: 2.2785 - val_categorical_accuracy: 0.4402\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6920 - categorical_accuracy: 0.6421 - val_loss: 2.0680 - val_categorical_accuracy: 0.4898\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5849 - categorical_accuracy: 0.6719 - val_loss: 2.1626 - val_categorical_accuracy: 0.4740\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5503 - categorical_accuracy: 0.6804 - val_loss: 2.1461 - val_categorical_accuracy: 0.4718\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4662 - categorical_accuracy: 0.7144 - val_loss: 2.0741 - val_categorical_accuracy: 0.4876\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4277 - categorical_accuracy: 0.7267 - val_loss: 2.0857 - val_categorical_accuracy: 0.4944\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4263 - categorical_accuracy: 0.7272 - val_loss: 2.1202 - val_categorical_accuracy: 0.4989\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3865 - categorical_accuracy: 0.7442 - val_loss: 2.1434 - val_categorical_accuracy: 0.4898\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3404 - categorical_accuracy: 0.7579 - val_loss: 2.1121 - val_categorical_accuracy: 0.5147\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.3366 - categorical_accuracy: 0.7678 - val_loss: 2.1437 - val_categorical_accuracy: 0.4966\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2915 - categorical_accuracy: 0.7650 - val_loss: 2.1919 - val_categorical_accuracy: 0.4808\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2501 - categorical_accuracy: 0.7915 - val_loss: 2.1790 - val_categorical_accuracy: 0.4808\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2441 - categorical_accuracy: 0.7929 - val_loss: 2.1990 - val_categorical_accuracy: 0.4853\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.2216 - categorical_accuracy: 0.7976 - val_loss: 2.1636 - val_categorical_accuracy: 0.4876\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.1954 - categorical_accuracy: 0.8095 - val_loss: 2.2076 - val_categorical_accuracy: 0.5034\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.1815 - categorical_accuracy: 0.8161 - val_loss: 2.1679 - val_categorical_accuracy: 0.4966\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.1679 - categorical_accuracy: 0.8213 - val_loss: 2.1696 - val_categorical_accuracy: 0.4898\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.1413 - categorical_accuracy: 0.8317 - val_loss: 2.2137 - val_categorical_accuracy: 0.4944\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.1089 - categorical_accuracy: 0.8392 - val_loss: 2.2374 - val_categorical_accuracy: 0.4921\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1067 - categorical_accuracy: 0.8444 - val_loss: 2.2701 - val_categorical_accuracy: 0.4944\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1009 - categorical_accuracy: 0.8487 - val_loss: 2.2476 - val_categorical_accuracy: 0.4831\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0768 - categorical_accuracy: 0.8511 - val_loss: 2.2530 - val_categorical_accuracy: 0.5034\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0437 - categorical_accuracy: 0.8610 - val_loss: 2.2609 - val_categorical_accuracy: 0.4966\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0671 - categorical_accuracy: 0.8591 - val_loss: 2.2895 - val_categorical_accuracy: 0.4989\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0255 - categorical_accuracy: 0.8738 - val_loss: 2.2874 - val_categorical_accuracy: 0.4921\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0034 - categorical_accuracy: 0.8813 - val_loss: 2.3072 - val_categorical_accuracy: 0.4898\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0166 - categorical_accuracy: 0.8742 - val_loss: 2.3360 - val_categorical_accuracy: 0.4966\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 0.9898 - categorical_accuracy: 0.8861 - val_loss: 2.3169 - val_categorical_accuracy: 0.5011\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 0.9743 - categorical_accuracy: 0.8955 - val_loss: 2.3329 - val_categorical_accuracy: 0.5011\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 0.9750 - categorical_accuracy: 0.8846 - val_loss: 2.3375 - val_categorical_accuracy: 0.5102\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 0.9604 - categorical_accuracy: 0.9054 - val_loss: 2.3551 - val_categorical_accuracy: 0.4944\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 0.9659 - categorical_accuracy: 0.8941 - val_loss: 2.3649 - val_categorical_accuracy: 0.4966\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9537 - categorical_accuracy: 0.8917 - val_loss: 2.3573 - val_categorical_accuracy: 0.5147\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9610 - categorical_accuracy: 0.8917 - val_loss: 2.3819 - val_categorical_accuracy: 0.5056\n",
      "2115/2115 [==============================] - 1s 373us/sample - loss: 0.7700 - categorical_accuracy: 0.9896\n",
      "443/443 [==============================] - 0s 381us/sample - loss: 2.3819 - categorical_accuracy: 0.5056\n",
      "train categorical_accuracy: 98.960%\n",
      "test categorical_accuracy: 50.564%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 22, 296, 16)       96        \n",
      "_________________________________________________________________\n",
      "elu_16 (ELU)                 (None, 22, 296, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 22, 296, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 22, 148, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 22, 148, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 22, 144, 32)       2592      \n",
      "_________________________________________________________________\n",
      "elu_17 (ELU)                 (None, 22, 144, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 22, 144, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 22, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 68, 64)        10304     \n",
      "_________________________________________________________________\n",
      "elu_18 (ELU)                 (None, 22, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 22, 68, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 22, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 22, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 47872)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 191492    \n",
      "=================================================================\n",
      "Total params: 204,748\n",
      "Trainable params: 204,616\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================350===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 11.1691 - categorical_accuracy: 0.2908 - val_loss: 11.0840 - val_categorical_accuracy: 0.3138\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 10.7493 - categorical_accuracy: 0.3248 - val_loss: 10.7982 - val_categorical_accuracy: 0.3273\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 9.2449 - categorical_accuracy: 0.3934 - val_loss: 9.0254 - val_categorical_accuracy: 0.3815\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 7.7599 - categorical_accuracy: 0.4265 - val_loss: 7.4989 - val_categorical_accuracy: 0.4221\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 5.6790 - categorical_accuracy: 0.4936 - val_loss: 5.7631 - val_categorical_accuracy: 0.4379\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 3.7427 - categorical_accuracy: 0.5442 - val_loss: 4.2380 - val_categorical_accuracy: 0.4176\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.8740 - categorical_accuracy: 0.6028 - val_loss: 3.3017 - val_categorical_accuracy: 0.4763\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.3193 - categorical_accuracy: 0.6270 - val_loss: 2.9604 - val_categorical_accuracy: 0.5034\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0841 - categorical_accuracy: 0.6572 - val_loss: 2.9426 - val_categorical_accuracy: 0.4673\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.9487 - categorical_accuracy: 0.6681 - val_loss: 2.7996 - val_categorical_accuracy: 0.4695\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8739 - categorical_accuracy: 0.6714 - val_loss: 2.7039 - val_categorical_accuracy: 0.4808\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7127 - categorical_accuracy: 0.7092 - val_loss: 2.5459 - val_categorical_accuracy: 0.4718\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6629 - categorical_accuracy: 0.7069 - val_loss: 2.4942 - val_categorical_accuracy: 0.5011\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5670 - categorical_accuracy: 0.7291 - val_loss: 2.4943 - val_categorical_accuracy: 0.5079\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5914 - categorical_accuracy: 0.7229 - val_loss: 2.6879 - val_categorical_accuracy: 0.5011\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6015 - categorical_accuracy: 0.7144 - val_loss: 2.4583 - val_categorical_accuracy: 0.4898\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4792 - categorical_accuracy: 0.7546 - val_loss: 2.4621 - val_categorical_accuracy: 0.5147\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3996 - categorical_accuracy: 0.7626 - val_loss: 2.4120 - val_categorical_accuracy: 0.5079\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4154 - categorical_accuracy: 0.7589 - val_loss: 2.5459 - val_categorical_accuracy: 0.5124\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4282 - categorical_accuracy: 0.7522 - val_loss: 2.5313 - val_categorical_accuracy: 0.5124\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3580 - categorical_accuracy: 0.7716 - val_loss: 2.4991 - val_categorical_accuracy: 0.5102\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3273 - categorical_accuracy: 0.7835 - val_loss: 2.3372 - val_categorical_accuracy: 0.5192\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3380 - categorical_accuracy: 0.7849 - val_loss: 2.3773 - val_categorical_accuracy: 0.5282\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2866 - categorical_accuracy: 0.7962 - val_loss: 2.3185 - val_categorical_accuracy: 0.5305\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3270 - categorical_accuracy: 0.7787 - val_loss: 2.4269 - val_categorical_accuracy: 0.5034\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2645 - categorical_accuracy: 0.7924 - val_loss: 2.2999 - val_categorical_accuracy: 0.5260\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2545 - categorical_accuracy: 0.8028 - val_loss: 2.5168 - val_categorical_accuracy: 0.4989\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2351 - categorical_accuracy: 0.8118 - val_loss: 2.5200 - val_categorical_accuracy: 0.5147\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2206 - categorical_accuracy: 0.8099 - val_loss: 2.3286 - val_categorical_accuracy: 0.5305\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2156 - categorical_accuracy: 0.8246 - val_loss: 2.4013 - val_categorical_accuracy: 0.5237\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2062 - categorical_accuracy: 0.8180 - val_loss: 2.4037 - val_categorical_accuracy: 0.5056\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1894 - categorical_accuracy: 0.8288 - val_loss: 2.3307 - val_categorical_accuracy: 0.5305\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1721 - categorical_accuracy: 0.8307 - val_loss: 2.4047 - val_categorical_accuracy: 0.5214\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1637 - categorical_accuracy: 0.8336 - val_loss: 2.3585 - val_categorical_accuracy: 0.5350\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1281 - categorical_accuracy: 0.8558 - val_loss: 2.3922 - val_categorical_accuracy: 0.5169\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.1482 - categorical_accuracy: 0.8392 - val_loss: 2.3913 - val_categorical_accuracy: 0.5237\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1180 - categorical_accuracy: 0.8563 - val_loss: 2.4564 - val_categorical_accuracy: 0.5124\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1256 - categorical_accuracy: 0.8520 - val_loss: 2.3443 - val_categorical_accuracy: 0.5372\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1008 - categorical_accuracy: 0.8530 - val_loss: 2.4048 - val_categorical_accuracy: 0.5237\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1005 - categorical_accuracy: 0.8530 - val_loss: 2.3868 - val_categorical_accuracy: 0.5440\n",
      "2115/2115 [==============================] - 1s 354us/sample - loss: 0.9373 - categorical_accuracy: 0.9305\n",
      "443/443 [==============================] - 0s 358us/sample - loss: 2.3868 - categorical_accuracy: 0.5440\n",
      "train categorical_accuracy: 93.050%\n",
      "test categorical_accuracy: 54.402%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 22, 346, 16)       96        \n",
      "_________________________________________________________________\n",
      "elu_19 (ELU)                 (None, 22, 346, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 22, 346, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 22, 173, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 173, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 22, 169, 32)       2592      \n",
      "_________________________________________________________________\n",
      "elu_20 (ELU)                 (None, 22, 169, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 22, 169, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 22, 84, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 22, 84, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 22, 80, 64)        10304     \n",
      "_________________________________________________________________\n",
      "elu_21 (ELU)                 (None, 22, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 22, 80, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 22, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 56320)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 225284    \n",
      "=================================================================\n",
      "Total params: 238,540\n",
      "Trainable params: 238,408\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================400===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 11.0739 - categorical_accuracy: 0.3035 - val_loss: 10.9991 - val_categorical_accuracy: 0.3318\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 9.6468 - categorical_accuracy: 0.3726 - val_loss: 10.4086 - val_categorical_accuracy: 0.3476\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 8.3372 - categorical_accuracy: 0.4194 - val_loss: 7.5201 - val_categorical_accuracy: 0.4063\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 5.3519 - categorical_accuracy: 0.4629 - val_loss: 4.9476 - val_categorical_accuracy: 0.3860\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.9236 - categorical_accuracy: 0.5357 - val_loss: 3.5476 - val_categorical_accuracy: 0.3950\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.3652 - categorical_accuracy: 0.5820 - val_loss: 3.1693 - val_categorical_accuracy: 0.4018\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0564 - categorical_accuracy: 0.6085 - val_loss: 3.0096 - val_categorical_accuracy: 0.4086\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.9217 - categorical_accuracy: 0.6279 - val_loss: 2.6923 - val_categorical_accuracy: 0.4537\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7411 - categorical_accuracy: 0.6652 - val_loss: 2.6870 - val_categorical_accuracy: 0.4492\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7065 - categorical_accuracy: 0.6870 - val_loss: 2.5800 - val_categorical_accuracy: 0.4650\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6470 - categorical_accuracy: 0.6861 - val_loss: 2.3131 - val_categorical_accuracy: 0.4808\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6209 - categorical_accuracy: 0.6965 - val_loss: 2.4973 - val_categorical_accuracy: 0.4470\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5333 - categorical_accuracy: 0.7329 - val_loss: 2.3672 - val_categorical_accuracy: 0.4831\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5130 - categorical_accuracy: 0.7206 - val_loss: 2.4892 - val_categorical_accuracy: 0.4628\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4275 - categorical_accuracy: 0.7437 - val_loss: 2.4263 - val_categorical_accuracy: 0.4560\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3811 - categorical_accuracy: 0.7674 - val_loss: 2.2363 - val_categorical_accuracy: 0.4989\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3356 - categorical_accuracy: 0.7868 - val_loss: 2.3523 - val_categorical_accuracy: 0.4740\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3370 - categorical_accuracy: 0.7830 - val_loss: 2.2346 - val_categorical_accuracy: 0.4989\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2959 - categorical_accuracy: 0.7929 - val_loss: 2.2353 - val_categorical_accuracy: 0.5056\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2414 - categorical_accuracy: 0.8180 - val_loss: 2.3177 - val_categorical_accuracy: 0.4966\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2470 - categorical_accuracy: 0.8061 - val_loss: 2.2585 - val_categorical_accuracy: 0.4989\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2154 - categorical_accuracy: 0.8165 - val_loss: 2.2867 - val_categorical_accuracy: 0.4876\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2208 - categorical_accuracy: 0.8109 - val_loss: 2.3549 - val_categorical_accuracy: 0.4921\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1562 - categorical_accuracy: 0.8378 - val_loss: 2.3765 - val_categorical_accuracy: 0.5034\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1654 - categorical_accuracy: 0.8364 - val_loss: 2.3414 - val_categorical_accuracy: 0.5079\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1322 - categorical_accuracy: 0.8544 - val_loss: 2.3302 - val_categorical_accuracy: 0.5124\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1042 - categorical_accuracy: 0.8615 - val_loss: 2.3065 - val_categorical_accuracy: 0.5011\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.1193 - categorical_accuracy: 0.8572 - val_loss: 2.3352 - val_categorical_accuracy: 0.4921\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.0807 - categorical_accuracy: 0.8652 - val_loss: 2.3333 - val_categorical_accuracy: 0.5056\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.0796 - categorical_accuracy: 0.8681 - val_loss: 2.3113 - val_categorical_accuracy: 0.5124\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.0719 - categorical_accuracy: 0.8686 - val_loss: 2.4254 - val_categorical_accuracy: 0.5169\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.0156 - categorical_accuracy: 0.8950 - val_loss: 2.4028 - val_categorical_accuracy: 0.5124\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.0117 - categorical_accuracy: 0.8950 - val_loss: 2.4102 - val_categorical_accuracy: 0.4966\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.0327 - categorical_accuracy: 0.8818 - val_loss: 2.3484 - val_categorical_accuracy: 0.5079\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9994 - categorical_accuracy: 0.8979 - val_loss: 2.3833 - val_categorical_accuracy: 0.5079\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9980 - categorical_accuracy: 0.9050 - val_loss: 2.4825 - val_categorical_accuracy: 0.5056\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9852 - categorical_accuracy: 0.9002 - val_loss: 2.5305 - val_categorical_accuracy: 0.5079\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9609 - categorical_accuracy: 0.9073 - val_loss: 2.3935 - val_categorical_accuracy: 0.5056\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9732 - categorical_accuracy: 0.9021 - val_loss: 2.3773 - val_categorical_accuracy: 0.5102\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.9609 - categorical_accuracy: 0.9069 - val_loss: 2.3784 - val_categorical_accuracy: 0.5124\n",
      "2115/2115 [==============================] - 1s 398us/sample - loss: 0.8124 - categorical_accuracy: 0.9853\n",
      "443/443 [==============================] - 0s 395us/sample - loss: 2.3784 - categorical_accuracy: 0.5124\n",
      "train categorical_accuracy: 98.534%\n",
      "test categorical_accuracy: 51.242%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 22, 396, 16)       96        \n",
      "_________________________________________________________________\n",
      "elu_22 (ELU)                 (None, 22, 396, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 22, 396, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 22, 198, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 22, 198, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 22, 194, 32)       2592      \n",
      "_________________________________________________________________\n",
      "elu_23 (ELU)                 (None, 22, 194, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 22, 194, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 22, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 22, 93, 64)        10304     \n",
      "_________________________________________________________________\n",
      "elu_24 (ELU)                 (None, 22, 93, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 22, 93, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 22, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 22, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64768)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 259076    \n",
      "=================================================================\n",
      "Total params: 272,332\n",
      "Trainable params: 272,200\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================450===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 3.1900 - categorical_accuracy: 0.2771 - val_loss: 2.9066 - val_categorical_accuracy: 0.3386\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 2s 986us/sample - loss: 2.7358 - categorical_accuracy: 0.3064 - val_loss: 2.5547 - val_categorical_accuracy: 0.3363\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 2s 989us/sample - loss: 2.4947 - categorical_accuracy: 0.3603 - val_loss: 2.4135 - val_categorical_accuracy: 0.3454\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 2s 983us/sample - loss: 2.3547 - categorical_accuracy: 0.3835 - val_loss: 2.2728 - val_categorical_accuracy: 0.3905\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 2s 980us/sample - loss: 2.2310 - categorical_accuracy: 0.4208 - val_loss: 2.1505 - val_categorical_accuracy: 0.4492\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 2s 988us/sample - loss: 2.1137 - categorical_accuracy: 0.4600 - val_loss: 2.0743 - val_categorical_accuracy: 0.4537\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 2s 985us/sample - loss: 2.0373 - categorical_accuracy: 0.4818 - val_loss: 2.0212 - val_categorical_accuracy: 0.4944\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 2s 982us/sample - loss: 1.9543 - categorical_accuracy: 0.5092 - val_loss: 1.9567 - val_categorical_accuracy: 0.5147\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 2s 985us/sample - loss: 1.8796 - categorical_accuracy: 0.5319 - val_loss: 1.9174 - val_categorical_accuracy: 0.5214\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.8374 - categorical_accuracy: 0.5376 - val_loss: 1.8804 - val_categorical_accuracy: 0.5124\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 2s 985us/sample - loss: 1.7922 - categorical_accuracy: 0.5461 - val_loss: 1.8594 - val_categorical_accuracy: 0.5214\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 2s 985us/sample - loss: 1.7758 - categorical_accuracy: 0.5589 - val_loss: 1.8189 - val_categorical_accuracy: 0.5463\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 2s 989us/sample - loss: 1.7225 - categorical_accuracy: 0.5735 - val_loss: 1.7868 - val_categorical_accuracy: 0.5643\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.6926 - categorical_accuracy: 0.5754 - val_loss: 1.7604 - val_categorical_accuracy: 0.5508\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.6631 - categorical_accuracy: 0.5863 - val_loss: 1.7501 - val_categorical_accuracy: 0.5643\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 2s 983us/sample - loss: 1.6319 - categorical_accuracy: 0.5995 - val_loss: 1.7320 - val_categorical_accuracy: 0.5508\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 2s 980us/sample - loss: 1.5855 - categorical_accuracy: 0.6165 - val_loss: 1.7079 - val_categorical_accuracy: 0.5553\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 2s 989us/sample - loss: 1.5884 - categorical_accuracy: 0.6009 - val_loss: 1.6984 - val_categorical_accuracy: 0.5553\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 2s 986us/sample - loss: 1.5777 - categorical_accuracy: 0.6128 - val_loss: 1.6999 - val_categorical_accuracy: 0.5801\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 2s 982us/sample - loss: 1.5458 - categorical_accuracy: 0.6326 - val_loss: 1.6789 - val_categorical_accuracy: 0.5801\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 2s 990us/sample - loss: 1.5378 - categorical_accuracy: 0.6279 - val_loss: 1.6797 - val_categorical_accuracy: 0.5801\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 2s 982us/sample - loss: 1.4974 - categorical_accuracy: 0.6473 - val_loss: 1.6480 - val_categorical_accuracy: 0.5847\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 2s 996us/sample - loss: 1.4899 - categorical_accuracy: 0.6397 - val_loss: 1.6594 - val_categorical_accuracy: 0.5711\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 2s 982us/sample - loss: 1.4806 - categorical_accuracy: 0.6548 - val_loss: 1.6476 - val_categorical_accuracy: 0.5824\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.4723 - categorical_accuracy: 0.6586 - val_loss: 1.6464 - val_categorical_accuracy: 0.5688\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 2s 985us/sample - loss: 1.4526 - categorical_accuracy: 0.6440 - val_loss: 1.6357 - val_categorical_accuracy: 0.5824\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 2s 979us/sample - loss: 1.4441 - categorical_accuracy: 0.6496 - val_loss: 1.6520 - val_categorical_accuracy: 0.5530\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 2s 984us/sample - loss: 1.4260 - categorical_accuracy: 0.6728 - val_loss: 1.6502 - val_categorical_accuracy: 0.5779\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 2s 982us/sample - loss: 1.4091 - categorical_accuracy: 0.6837 - val_loss: 1.6369 - val_categorical_accuracy: 0.5779\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 2s 993us/sample - loss: 1.3927 - categorical_accuracy: 0.6790 - val_loss: 1.6349 - val_categorical_accuracy: 0.5734\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.3844 - categorical_accuracy: 0.6799 - val_loss: 1.6452 - val_categorical_accuracy: 0.5801\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 2s 990us/sample - loss: 1.3748 - categorical_accuracy: 0.6861 - val_loss: 1.6141 - val_categorical_accuracy: 0.5779\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 2s 978us/sample - loss: 1.3567 - categorical_accuracy: 0.6979 - val_loss: 1.6391 - val_categorical_accuracy: 0.5666\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 2s 988us/sample - loss: 1.3604 - categorical_accuracy: 0.6856 - val_loss: 1.6270 - val_categorical_accuracy: 0.5801\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.3561 - categorical_accuracy: 0.6714 - val_loss: 1.6485 - val_categorical_accuracy: 0.5553\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.3473 - categorical_accuracy: 0.6988 - val_loss: 1.6181 - val_categorical_accuracy: 0.5756\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 2s 980us/sample - loss: 1.3353 - categorical_accuracy: 0.6922 - val_loss: 1.6071 - val_categorical_accuracy: 0.5666\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 2s 981us/sample - loss: 1.3149 - categorical_accuracy: 0.7026 - val_loss: 1.6183 - val_categorical_accuracy: 0.5756\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 2s 974us/sample - loss: 1.3069 - categorical_accuracy: 0.7102 - val_loss: 1.6217 - val_categorical_accuracy: 0.5621\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 2s 982us/sample - loss: 1.2912 - categorical_accuracy: 0.7069 - val_loss: 1.6199 - val_categorical_accuracy: 0.5688\n",
      "2115/2115 [==============================] - 1s 316us/sample - loss: 1.0887 - categorical_accuracy: 0.8336\n",
      "443/443 [==============================] - 0s 311us/sample - loss: 1.6199 - categorical_accuracy: 0.5688\n",
      "train categorical_accuracy: 83.357%\n",
      "test categorical_accuracy: 56.885%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 22, 441, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_25 (ELU)                 (None, 22, 441, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 22, 441, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 22, 110, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 22, 110, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 22, 101, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_26 (ELU)                 (None, 22, 101, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 22, 101, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 22, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 22, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 22, 16, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_27 (ELU)                 (None, 22, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 22, 16, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 22, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 22, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 2, 4, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_28 (ELU)                 (None, 2, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 2, 4, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 199,332\n",
      "Trainable params: 199,196\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================500===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 3.5661 - categorical_accuracy: 0.2719 - val_loss: 2.8932 - val_categorical_accuracy: 0.2664\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.7778 - categorical_accuracy: 0.2879 - val_loss: 2.5713 - val_categorical_accuracy: 0.2822\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.5912 - categorical_accuracy: 0.2827 - val_loss: 2.3936 - val_categorical_accuracy: 0.3228\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.3890 - categorical_accuracy: 0.3291 - val_loss: 2.2698 - val_categorical_accuracy: 0.3318\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.2654 - categorical_accuracy: 0.3466 - val_loss: 2.1607 - val_categorical_accuracy: 0.3815\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.1343 - categorical_accuracy: 0.4071 - val_loss: 2.0722 - val_categorical_accuracy: 0.4312\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.0833 - categorical_accuracy: 0.4099 - val_loss: 2.0090 - val_categorical_accuracy: 0.4153\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.9906 - categorical_accuracy: 0.4463 - val_loss: 1.9467 - val_categorical_accuracy: 0.4740\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.9013 - categorical_accuracy: 0.4733 - val_loss: 1.9130 - val_categorical_accuracy: 0.4605\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.8416 - categorical_accuracy: 0.4927 - val_loss: 1.8550 - val_categorical_accuracy: 0.4786\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7851 - categorical_accuracy: 0.5191 - val_loss: 1.8351 - val_categorical_accuracy: 0.4989\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7784 - categorical_accuracy: 0.5158 - val_loss: 1.7805 - val_categorical_accuracy: 0.4898\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6970 - categorical_accuracy: 0.5390 - val_loss: 1.7415 - val_categorical_accuracy: 0.5079\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6776 - categorical_accuracy: 0.5329 - val_loss: 1.7317 - val_categorical_accuracy: 0.5305\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6138 - categorical_accuracy: 0.5702 - val_loss: 1.6977 - val_categorical_accuracy: 0.5485\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6264 - categorical_accuracy: 0.5622 - val_loss: 1.6600 - val_categorical_accuracy: 0.5621\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5546 - categorical_accuracy: 0.5962 - val_loss: 1.6984 - val_categorical_accuracy: 0.5305\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5482 - categorical_accuracy: 0.6005 - val_loss: 1.6438 - val_categorical_accuracy: 0.5553\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5395 - categorical_accuracy: 0.5820 - val_loss: 1.6435 - val_categorical_accuracy: 0.5598\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5229 - categorical_accuracy: 0.6000 - val_loss: 1.6127 - val_categorical_accuracy: 0.5666\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4758 - categorical_accuracy: 0.6203 - val_loss: 1.5896 - val_categorical_accuracy: 0.5959\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4383 - categorical_accuracy: 0.6388 - val_loss: 1.5891 - val_categorical_accuracy: 0.5756\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4443 - categorical_accuracy: 0.6217 - val_loss: 1.5785 - val_categorical_accuracy: 0.5756\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4255 - categorical_accuracy: 0.6340 - val_loss: 1.5672 - val_categorical_accuracy: 0.5937\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4087 - categorical_accuracy: 0.6411 - val_loss: 1.5882 - val_categorical_accuracy: 0.5598\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4099 - categorical_accuracy: 0.6392 - val_loss: 1.5563 - val_categorical_accuracy: 0.5869\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3931 - categorical_accuracy: 0.6567 - val_loss: 1.5407 - val_categorical_accuracy: 0.6027\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3616 - categorical_accuracy: 0.6671 - val_loss: 1.5465 - val_categorical_accuracy: 0.5937\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3431 - categorical_accuracy: 0.6752 - val_loss: 1.5418 - val_categorical_accuracy: 0.5824\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3615 - categorical_accuracy: 0.6638 - val_loss: 1.5514 - val_categorical_accuracy: 0.5688\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3409 - categorical_accuracy: 0.6742 - val_loss: 1.5289 - val_categorical_accuracy: 0.5779\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3190 - categorical_accuracy: 0.6766 - val_loss: 1.5291 - val_categorical_accuracy: 0.5801\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3123 - categorical_accuracy: 0.6837 - val_loss: 1.5495 - val_categorical_accuracy: 0.5914\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2898 - categorical_accuracy: 0.6875 - val_loss: 1.5221 - val_categorical_accuracy: 0.5869\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2810 - categorical_accuracy: 0.6865 - val_loss: 1.5469 - val_categorical_accuracy: 0.5688\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2707 - categorical_accuracy: 0.6894 - val_loss: 1.5368 - val_categorical_accuracy: 0.5598\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2840 - categorical_accuracy: 0.6903 - val_loss: 1.5530 - val_categorical_accuracy: 0.5711\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2634 - categorical_accuracy: 0.6927 - val_loss: 1.5108 - val_categorical_accuracy: 0.5892\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2638 - categorical_accuracy: 0.6936 - val_loss: 1.5201 - val_categorical_accuracy: 0.6095\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2371 - categorical_accuracy: 0.7026 - val_loss: 1.5255 - val_categorical_accuracy: 0.5892\n",
      "2115/2115 [==============================] - 1s 341us/sample - loss: 1.0338 - categorical_accuracy: 0.8199\n",
      "443/443 [==============================] - 0s 346us/sample - loss: 1.5255 - categorical_accuracy: 0.5892\n",
      "train categorical_accuracy: 81.986%\n",
      "test categorical_accuracy: 58.916%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 22, 491, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_29 (ELU)                 (None, 22, 491, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 22, 491, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 22, 122, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 122, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 22, 113, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_30 (ELU)                 (None, 22, 113, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 22, 113, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 22, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 22, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 22, 19, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_31 (ELU)                 (None, 22, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 22, 19, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 22, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 22, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 2, 4, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_32 (ELU)                 (None, 2, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 2, 4, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 199,332\n",
      "Trainable params: 199,196\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================550===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 3.4313 - categorical_accuracy: 0.2600 - val_loss: 3.1388 - val_categorical_accuracy: 0.2460\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.7807 - categorical_accuracy: 0.2969 - val_loss: 2.6046 - val_categorical_accuracy: 0.3138\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.5902 - categorical_accuracy: 0.2969 - val_loss: 2.4170 - val_categorical_accuracy: 0.3657\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.4308 - categorical_accuracy: 0.3220 - val_loss: 2.3001 - val_categorical_accuracy: 0.3521\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.2662 - categorical_accuracy: 0.3716 - val_loss: 2.1991 - val_categorical_accuracy: 0.4086\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.1746 - categorical_accuracy: 0.3778 - val_loss: 2.1223 - val_categorical_accuracy: 0.4108\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.0785 - categorical_accuracy: 0.4184 - val_loss: 2.0447 - val_categorical_accuracy: 0.4379\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 2.0059 - categorical_accuracy: 0.4444 - val_loss: 1.9899 - val_categorical_accuracy: 0.4831\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.9399 - categorical_accuracy: 0.4492 - val_loss: 1.9924 - val_categorical_accuracy: 0.4673\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.9172 - categorical_accuracy: 0.4591 - val_loss: 1.8978 - val_categorical_accuracy: 0.4718\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.8390 - categorical_accuracy: 0.4851 - val_loss: 1.8753 - val_categorical_accuracy: 0.4740\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.8039 - categorical_accuracy: 0.5083 - val_loss: 1.8357 - val_categorical_accuracy: 0.5147\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7425 - categorical_accuracy: 0.5352 - val_loss: 1.8025 - val_categorical_accuracy: 0.4898\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7027 - categorical_accuracy: 0.5470 - val_loss: 1.7640 - val_categorical_accuracy: 0.5147\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6704 - categorical_accuracy: 0.5650 - val_loss: 1.7665 - val_categorical_accuracy: 0.5237\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6536 - categorical_accuracy: 0.5626 - val_loss: 1.7264 - val_categorical_accuracy: 0.5192\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.6202 - categorical_accuracy: 0.5688 - val_loss: 1.7050 - val_categorical_accuracy: 0.5214\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5782 - categorical_accuracy: 0.5953 - val_loss: 1.6869 - val_categorical_accuracy: 0.5553\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5767 - categorical_accuracy: 0.5929 - val_loss: 1.6760 - val_categorical_accuracy: 0.5418\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5507 - categorical_accuracy: 0.5929 - val_loss: 1.6898 - val_categorical_accuracy: 0.5124\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5340 - categorical_accuracy: 0.6028 - val_loss: 1.6527 - val_categorical_accuracy: 0.5282\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5244 - categorical_accuracy: 0.6099 - val_loss: 1.6563 - val_categorical_accuracy: 0.5237\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.5154 - categorical_accuracy: 0.5901 - val_loss: 1.6402 - val_categorical_accuracy: 0.5530\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4767 - categorical_accuracy: 0.6175 - val_loss: 1.6433 - val_categorical_accuracy: 0.5372\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4414 - categorical_accuracy: 0.6288 - val_loss: 1.6396 - val_categorical_accuracy: 0.5508\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4277 - categorical_accuracy: 0.6388 - val_loss: 1.6423 - val_categorical_accuracy: 0.5508\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4489 - categorical_accuracy: 0.6217 - val_loss: 1.6222 - val_categorical_accuracy: 0.5598\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.4158 - categorical_accuracy: 0.6345 - val_loss: 1.6234 - val_categorical_accuracy: 0.5553\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3960 - categorical_accuracy: 0.6435 - val_loss: 1.6018 - val_categorical_accuracy: 0.5801\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3767 - categorical_accuracy: 0.6544 - val_loss: 1.5938 - val_categorical_accuracy: 0.5598\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3838 - categorical_accuracy: 0.6421 - val_loss: 1.5883 - val_categorical_accuracy: 0.5711\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3551 - categorical_accuracy: 0.6714 - val_loss: 1.5849 - val_categorical_accuracy: 0.5734\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3413 - categorical_accuracy: 0.6733 - val_loss: 1.5897 - val_categorical_accuracy: 0.5666\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3520 - categorical_accuracy: 0.6657 - val_loss: 1.6344 - val_categorical_accuracy: 0.5327\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3438 - categorical_accuracy: 0.6652 - val_loss: 1.6042 - val_categorical_accuracy: 0.5530\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3213 - categorical_accuracy: 0.6809 - val_loss: 1.5842 - val_categorical_accuracy: 0.5576\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2993 - categorical_accuracy: 0.6875 - val_loss: 1.6180 - val_categorical_accuracy: 0.5372\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.3310 - categorical_accuracy: 0.6690 - val_loss: 1.5876 - val_categorical_accuracy: 0.5734\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2756 - categorical_accuracy: 0.6941 - val_loss: 1.5817 - val_categorical_accuracy: 0.5621\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.2667 - categorical_accuracy: 0.7007 - val_loss: 1.5933 - val_categorical_accuracy: 0.5598\n",
      "2115/2115 [==============================] - 1s 365us/sample - loss: 1.0894 - categorical_accuracy: 0.8005\n",
      "443/443 [==============================] - 0s 362us/sample - loss: 1.5933 - categorical_accuracy: 0.5598\n",
      "train categorical_accuracy: 80.047%\n",
      "test categorical_accuracy: 55.982%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 22, 541, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_33 (ELU)                 (None, 22, 541, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 22, 541, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 22, 135, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 22, 135, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 22, 126, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_34 (ELU)                 (None, 22, 126, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 22, 126, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 22, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 22, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 22, 22, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_35 (ELU)                 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 22, 22, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 22, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 22, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 2, 5, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_36 (ELU)                 (None, 2, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 2, 5, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 199,332\n",
      "Trainable params: 199,196\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================600===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 3.2786 - categorical_accuracy: 0.2530 - val_loss: 2.8257 - val_categorical_accuracy: 0.2438\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.7481 - categorical_accuracy: 0.2629 - val_loss: 2.5363 - val_categorical_accuracy: 0.2822\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.5242 - categorical_accuracy: 0.3040 - val_loss: 2.3771 - val_categorical_accuracy: 0.3363\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.3523 - categorical_accuracy: 0.3258 - val_loss: 2.2397 - val_categorical_accuracy: 0.3544\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.2217 - categorical_accuracy: 0.3749 - val_loss: 2.1415 - val_categorical_accuracy: 0.3950\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.1164 - categorical_accuracy: 0.3972 - val_loss: 2.0627 - val_categorical_accuracy: 0.4153\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0204 - categorical_accuracy: 0.4340 - val_loss: 2.0266 - val_categorical_accuracy: 0.4041\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.9417 - categorical_accuracy: 0.4586 - val_loss: 1.9309 - val_categorical_accuracy: 0.4853\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8683 - categorical_accuracy: 0.5050 - val_loss: 1.8788 - val_categorical_accuracy: 0.5079\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8220 - categorical_accuracy: 0.5083 - val_loss: 1.8404 - val_categorical_accuracy: 0.5147\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7776 - categorical_accuracy: 0.5201 - val_loss: 1.7971 - val_categorical_accuracy: 0.5214\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7282 - categorical_accuracy: 0.5442 - val_loss: 1.7679 - val_categorical_accuracy: 0.5598\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6859 - categorical_accuracy: 0.5518 - val_loss: 1.7800 - val_categorical_accuracy: 0.5260\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6720 - categorical_accuracy: 0.5527 - val_loss: 1.7108 - val_categorical_accuracy: 0.5553\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6319 - categorical_accuracy: 0.5645 - val_loss: 1.7053 - val_categorical_accuracy: 0.5485\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6038 - categorical_accuracy: 0.5697 - val_loss: 1.6625 - val_categorical_accuracy: 0.5530\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5603 - categorical_accuracy: 0.5967 - val_loss: 1.6633 - val_categorical_accuracy: 0.5485\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5597 - categorical_accuracy: 0.6024 - val_loss: 1.6453 - val_categorical_accuracy: 0.5598\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5362 - categorical_accuracy: 0.6000 - val_loss: 1.6355 - val_categorical_accuracy: 0.5756\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5052 - categorical_accuracy: 0.6222 - val_loss: 1.6218 - val_categorical_accuracy: 0.5598\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5026 - categorical_accuracy: 0.6222 - val_loss: 1.6124 - val_categorical_accuracy: 0.5892\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4618 - categorical_accuracy: 0.6374 - val_loss: 1.6248 - val_categorical_accuracy: 0.5598\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4417 - categorical_accuracy: 0.6416 - val_loss: 1.5946 - val_categorical_accuracy: 0.5711\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4294 - categorical_accuracy: 0.6430 - val_loss: 1.5711 - val_categorical_accuracy: 0.5779\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4108 - categorical_accuracy: 0.6530 - val_loss: 1.5739 - val_categorical_accuracy: 0.5824\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4139 - categorical_accuracy: 0.6411 - val_loss: 1.5786 - val_categorical_accuracy: 0.5824\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3787 - categorical_accuracy: 0.6662 - val_loss: 1.5667 - val_categorical_accuracy: 0.5982\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3770 - categorical_accuracy: 0.6558 - val_loss: 1.5591 - val_categorical_accuracy: 0.5734\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3684 - categorical_accuracy: 0.6492 - val_loss: 1.5677 - val_categorical_accuracy: 0.5824\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3769 - categorical_accuracy: 0.6515 - val_loss: 1.5628 - val_categorical_accuracy: 0.5711\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3429 - categorical_accuracy: 0.6738 - val_loss: 1.5775 - val_categorical_accuracy: 0.5892\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3356 - categorical_accuracy: 0.6700 - val_loss: 1.5427 - val_categorical_accuracy: 0.5711\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3357 - categorical_accuracy: 0.6638 - val_loss: 1.5491 - val_categorical_accuracy: 0.5779\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3255 - categorical_accuracy: 0.6809 - val_loss: 1.5548 - val_categorical_accuracy: 0.6005\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2883 - categorical_accuracy: 0.6908 - val_loss: 1.5383 - val_categorical_accuracy: 0.5869\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2906 - categorical_accuracy: 0.6917 - val_loss: 1.5298 - val_categorical_accuracy: 0.5914\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2701 - categorical_accuracy: 0.6922 - val_loss: 1.5337 - val_categorical_accuracy: 0.5824\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2872 - categorical_accuracy: 0.6875 - val_loss: 1.5320 - val_categorical_accuracy: 0.5824\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2872 - categorical_accuracy: 0.6908 - val_loss: 1.5514 - val_categorical_accuracy: 0.5959\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2625 - categorical_accuracy: 0.7092 - val_loss: 1.5304 - val_categorical_accuracy: 0.6072\n",
      "2115/2115 [==============================] - 1s 405us/sample - loss: 1.0526 - categorical_accuracy: 0.8255\n",
      "443/443 [==============================] - 0s 416us/sample - loss: 1.5304 - categorical_accuracy: 0.6072\n",
      "train categorical_accuracy: 82.553%\n",
      "test categorical_accuracy: 60.722%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 22, 591, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_37 (ELU)                 (None, 22, 591, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 22, 591, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 22, 147, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 22, 147, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 22, 138, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_38 (ELU)                 (None, 22, 138, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 22, 138, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 22, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 22, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 22, 25, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_39 (ELU)                 (None, 22, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 22, 25, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 22, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 22, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 2, 6, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_40 (ELU)                 (None, 2, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 2, 6, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 199,332\n",
      "Trainable params: 199,196\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================650===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 3.2076 - categorical_accuracy: 0.2818 - val_loss: 2.7760 - val_categorical_accuracy: 0.3183\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.7490 - categorical_accuracy: 0.3210 - val_loss: 2.5642 - val_categorical_accuracy: 0.3995\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.5465 - categorical_accuracy: 0.3475 - val_loss: 2.4137 - val_categorical_accuracy: 0.4199\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.3803 - categorical_accuracy: 0.3820 - val_loss: 2.3092 - val_categorical_accuracy: 0.4312\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.2824 - categorical_accuracy: 0.3972 - val_loss: 2.2109 - val_categorical_accuracy: 0.4560\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.1807 - categorical_accuracy: 0.4402 - val_loss: 2.1378 - val_categorical_accuracy: 0.4515\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0845 - categorical_accuracy: 0.4634 - val_loss: 2.1173 - val_categorical_accuracy: 0.4402\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0460 - categorical_accuracy: 0.4662 - val_loss: 2.0115 - val_categorical_accuracy: 0.5260\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.9514 - categorical_accuracy: 0.4936 - val_loss: 1.9508 - val_categorical_accuracy: 0.5237\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8857 - categorical_accuracy: 0.5281 - val_loss: 1.9111 - val_categorical_accuracy: 0.5485\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8455 - categorical_accuracy: 0.5423 - val_loss: 1.8757 - val_categorical_accuracy: 0.5260\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7770 - categorical_accuracy: 0.5485 - val_loss: 1.8623 - val_categorical_accuracy: 0.5169\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7614 - categorical_accuracy: 0.5650 - val_loss: 1.8269 - val_categorical_accuracy: 0.5305\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7406 - categorical_accuracy: 0.5655 - val_loss: 1.7885 - val_categorical_accuracy: 0.5553\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7142 - categorical_accuracy: 0.5669 - val_loss: 1.7843 - val_categorical_accuracy: 0.5530\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6752 - categorical_accuracy: 0.5820 - val_loss: 1.7919 - val_categorical_accuracy: 0.5418\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6420 - categorical_accuracy: 0.6019 - val_loss: 1.7751 - val_categorical_accuracy: 0.5530\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6474 - categorical_accuracy: 0.6000 - val_loss: 1.7620 - val_categorical_accuracy: 0.5485\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6070 - categorical_accuracy: 0.6043 - val_loss: 1.7497 - val_categorical_accuracy: 0.5598\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5738 - categorical_accuracy: 0.6317 - val_loss: 1.7167 - val_categorical_accuracy: 0.5666\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5555 - categorical_accuracy: 0.6336 - val_loss: 1.6977 - val_categorical_accuracy: 0.5801\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5332 - categorical_accuracy: 0.6336 - val_loss: 1.6890 - val_categorical_accuracy: 0.5801\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5264 - categorical_accuracy: 0.6416 - val_loss: 1.6818 - val_categorical_accuracy: 0.5869\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5012 - categorical_accuracy: 0.6459 - val_loss: 1.6724 - val_categorical_accuracy: 0.5847\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4903 - categorical_accuracy: 0.6402 - val_loss: 1.6638 - val_categorical_accuracy: 0.5892\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4998 - categorical_accuracy: 0.6426 - val_loss: 1.6695 - val_categorical_accuracy: 0.5688\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4688 - categorical_accuracy: 0.6392 - val_loss: 1.6889 - val_categorical_accuracy: 0.5598\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4360 - categorical_accuracy: 0.6804 - val_loss: 1.6508 - val_categorical_accuracy: 0.5869\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4502 - categorical_accuracy: 0.6582 - val_loss: 1.6619 - val_categorical_accuracy: 0.5801\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4394 - categorical_accuracy: 0.6676 - val_loss: 1.6477 - val_categorical_accuracy: 0.5892\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4154 - categorical_accuracy: 0.6733 - val_loss: 1.6497 - val_categorical_accuracy: 0.5982\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4100 - categorical_accuracy: 0.6785 - val_loss: 1.6474 - val_categorical_accuracy: 0.5801\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3879 - categorical_accuracy: 0.6799 - val_loss: 1.6432 - val_categorical_accuracy: 0.5869\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3802 - categorical_accuracy: 0.6861 - val_loss: 1.6349 - val_categorical_accuracy: 0.5801\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3641 - categorical_accuracy: 0.7031 - val_loss: 1.6708 - val_categorical_accuracy: 0.5530\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3452 - categorical_accuracy: 0.7026 - val_loss: 1.6233 - val_categorical_accuracy: 0.5937\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3575 - categorical_accuracy: 0.7031 - val_loss: 1.6381 - val_categorical_accuracy: 0.5824\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3542 - categorical_accuracy: 0.6870 - val_loss: 1.6797 - val_categorical_accuracy: 0.5508\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3466 - categorical_accuracy: 0.6974 - val_loss: 1.6318 - val_categorical_accuracy: 0.5779\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3448 - categorical_accuracy: 0.6913 - val_loss: 1.6334 - val_categorical_accuracy: 0.5847\n",
      "2115/2115 [==============================] - 1s 431us/sample - loss: 1.1296 - categorical_accuracy: 0.8307\n",
      "443/443 [==============================] - 0s 426us/sample - loss: 1.6334 - categorical_accuracy: 0.5847\n",
      "train categorical_accuracy: 83.073%\n",
      "test categorical_accuracy: 58.465%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 22, 641, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_41 (ELU)                 (None, 22, 641, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 22, 641, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 22, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 22, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 22, 151, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_42 (ELU)                 (None, 22, 151, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 22, 151, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 22, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 22, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 22, 28, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_43 (ELU)                 (None, 22, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 22, 28, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 22, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 22, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 2, 7, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_44 (ELU)                 (None, 2, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 2, 7, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 199,332\n",
      "Trainable params: 199,196\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================700===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 3.3542 - categorical_accuracy: 0.2719 - val_loss: 2.7790 - val_categorical_accuracy: 0.3770\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.7710 - categorical_accuracy: 0.2846 - val_loss: 2.5999 - val_categorical_accuracy: 0.2799\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.5162 - categorical_accuracy: 0.3466 - val_loss: 2.3665 - val_categorical_accuracy: 0.3973\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.3491 - categorical_accuracy: 0.3574 - val_loss: 2.2496 - val_categorical_accuracy: 0.3860\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.2105 - categorical_accuracy: 0.4014 - val_loss: 2.1740 - val_categorical_accuracy: 0.3612\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0964 - categorical_accuracy: 0.4388 - val_loss: 2.0755 - val_categorical_accuracy: 0.4424\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0361 - categorical_accuracy: 0.4421 - val_loss: 2.0313 - val_categorical_accuracy: 0.4876\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.9554 - categorical_accuracy: 0.4709 - val_loss: 1.9704 - val_categorical_accuracy: 0.4673\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8915 - categorical_accuracy: 0.4974 - val_loss: 1.9466 - val_categorical_accuracy: 0.4808\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8426 - categorical_accuracy: 0.5144 - val_loss: 1.8718 - val_categorical_accuracy: 0.5169\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7798 - categorical_accuracy: 0.5362 - val_loss: 1.8339 - val_categorical_accuracy: 0.5192\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7621 - categorical_accuracy: 0.5362 - val_loss: 1.7993 - val_categorical_accuracy: 0.5350\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6977 - categorical_accuracy: 0.5636 - val_loss: 1.7590 - val_categorical_accuracy: 0.5440\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6541 - categorical_accuracy: 0.5745 - val_loss: 1.7568 - val_categorical_accuracy: 0.5260\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6236 - categorical_accuracy: 0.5920 - val_loss: 1.7102 - val_categorical_accuracy: 0.5440\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6140 - categorical_accuracy: 0.5835 - val_loss: 1.7000 - val_categorical_accuracy: 0.5440\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5816 - categorical_accuracy: 0.5915 - val_loss: 1.7025 - val_categorical_accuracy: 0.5169\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5460 - categorical_accuracy: 0.6132 - val_loss: 1.6806 - val_categorical_accuracy: 0.5485\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5407 - categorical_accuracy: 0.6109 - val_loss: 1.6751 - val_categorical_accuracy: 0.5553\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5155 - categorical_accuracy: 0.6246 - val_loss: 1.6621 - val_categorical_accuracy: 0.5508\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4951 - categorical_accuracy: 0.6303 - val_loss: 1.6511 - val_categorical_accuracy: 0.5666\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4779 - categorical_accuracy: 0.6255 - val_loss: 1.6274 - val_categorical_accuracy: 0.5734\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4791 - categorical_accuracy: 0.6260 - val_loss: 1.6291 - val_categorical_accuracy: 0.5756\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4420 - categorical_accuracy: 0.6478 - val_loss: 1.6023 - val_categorical_accuracy: 0.5869\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4178 - categorical_accuracy: 0.6478 - val_loss: 1.6029 - val_categorical_accuracy: 0.5643\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4112 - categorical_accuracy: 0.6548 - val_loss: 1.6008 - val_categorical_accuracy: 0.5688\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4111 - categorical_accuracy: 0.6534 - val_loss: 1.5910 - val_categorical_accuracy: 0.5666\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3737 - categorical_accuracy: 0.6700 - val_loss: 1.5911 - val_categorical_accuracy: 0.5621\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3849 - categorical_accuracy: 0.6648 - val_loss: 1.6012 - val_categorical_accuracy: 0.5598\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3455 - categorical_accuracy: 0.6657 - val_loss: 1.6107 - val_categorical_accuracy: 0.5598\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3461 - categorical_accuracy: 0.6766 - val_loss: 1.6126 - val_categorical_accuracy: 0.5553\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3413 - categorical_accuracy: 0.6752 - val_loss: 1.5807 - val_categorical_accuracy: 0.5621\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3109 - categorical_accuracy: 0.7017 - val_loss: 1.5812 - val_categorical_accuracy: 0.5801\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3081 - categorical_accuracy: 0.7012 - val_loss: 1.6081 - val_categorical_accuracy: 0.5711\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2871 - categorical_accuracy: 0.6960 - val_loss: 1.6026 - val_categorical_accuracy: 0.5598\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2959 - categorical_accuracy: 0.6950 - val_loss: 1.5935 - val_categorical_accuracy: 0.5576\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2851 - categorical_accuracy: 0.6898 - val_loss: 1.5962 - val_categorical_accuracy: 0.5598\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2692 - categorical_accuracy: 0.7035 - val_loss: 1.6010 - val_categorical_accuracy: 0.5508\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2557 - categorical_accuracy: 0.7012 - val_loss: 1.6427 - val_categorical_accuracy: 0.5530\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2506 - categorical_accuracy: 0.7026 - val_loss: 1.6086 - val_categorical_accuracy: 0.5643\n",
      "2115/2115 [==============================] - 1s 452us/sample - loss: 1.0368 - categorical_accuracy: 0.8284\n",
      "443/443 [==============================] - 0s 453us/sample - loss: 1.6086 - categorical_accuracy: 0.5643\n",
      "train categorical_accuracy: 82.837%\n",
      "test categorical_accuracy: 56.433%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 22, 691, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_45 (ELU)                 (None, 22, 691, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 22, 691, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 22, 172, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 22, 172, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 22, 163, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_46 (ELU)                 (None, 22, 163, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 22, 163, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 22, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 22, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 22, 31, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_47 (ELU)                 (None, 22, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 22, 31, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 22, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 22, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 2, 7, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_48 (ELU)                 (None, 2, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 2, 7, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 199,332\n",
      "Trainable params: 199,196\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================750===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 3.3956 - categorical_accuracy: 0.2827 - val_loss: 2.9756 - val_categorical_accuracy: 0.3025\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.8435 - categorical_accuracy: 0.2979 - val_loss: 2.5818 - val_categorical_accuracy: 0.3499\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.6429 - categorical_accuracy: 0.3229 - val_loss: 2.4335 - val_categorical_accuracy: 0.3905\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.5014 - categorical_accuracy: 0.3229 - val_loss: 2.3398 - val_categorical_accuracy: 0.3567\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.3310 - categorical_accuracy: 0.3778 - val_loss: 2.2115 - val_categorical_accuracy: 0.4334\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.2363 - categorical_accuracy: 0.4038 - val_loss: 2.1375 - val_categorical_accuracy: 0.4289\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.1259 - categorical_accuracy: 0.4426 - val_loss: 2.0771 - val_categorical_accuracy: 0.4447\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 2.0277 - categorical_accuracy: 0.4913 - val_loss: 2.0265 - val_categorical_accuracy: 0.4515\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.9844 - categorical_accuracy: 0.4884 - val_loss: 1.9664 - val_categorical_accuracy: 0.5034\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8793 - categorical_accuracy: 0.5324 - val_loss: 1.9302 - val_categorical_accuracy: 0.5034\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8413 - categorical_accuracy: 0.5485 - val_loss: 1.9425 - val_categorical_accuracy: 0.4921\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7812 - categorical_accuracy: 0.5716 - val_loss: 1.9172 - val_categorical_accuracy: 0.4876\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7219 - categorical_accuracy: 0.5986 - val_loss: 1.8441 - val_categorical_accuracy: 0.5169\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7068 - categorical_accuracy: 0.6000 - val_loss: 1.8439 - val_categorical_accuracy: 0.5034\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6744 - categorical_accuracy: 0.6057 - val_loss: 1.8281 - val_categorical_accuracy: 0.5169\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.6615 - categorical_accuracy: 0.5924 - val_loss: 1.8061 - val_categorical_accuracy: 0.5079\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5956 - categorical_accuracy: 0.6359 - val_loss: 1.8042 - val_categorical_accuracy: 0.5147\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5986 - categorical_accuracy: 0.6241 - val_loss: 1.7719 - val_categorical_accuracy: 0.5169\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5548 - categorical_accuracy: 0.6284 - val_loss: 1.7531 - val_categorical_accuracy: 0.5169\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5205 - categorical_accuracy: 0.6591 - val_loss: 1.7694 - val_categorical_accuracy: 0.5102\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.5016 - categorical_accuracy: 0.6686 - val_loss: 1.7585 - val_categorical_accuracy: 0.5260\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4996 - categorical_accuracy: 0.6657 - val_loss: 1.7259 - val_categorical_accuracy: 0.5327\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4647 - categorical_accuracy: 0.6809 - val_loss: 1.7188 - val_categorical_accuracy: 0.5350\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4310 - categorical_accuracy: 0.6879 - val_loss: 1.7060 - val_categorical_accuracy: 0.5305\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.4348 - categorical_accuracy: 0.6742 - val_loss: 1.7185 - val_categorical_accuracy: 0.5327\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.4239 - categorical_accuracy: 0.6823 - val_loss: 1.7009 - val_categorical_accuracy: 0.5372\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.3875 - categorical_accuracy: 0.7017 - val_loss: 1.7211 - val_categorical_accuracy: 0.5282\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3835 - categorical_accuracy: 0.6988 - val_loss: 1.7182 - val_categorical_accuracy: 0.5237\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3780 - categorical_accuracy: 0.7111 - val_loss: 1.7108 - val_categorical_accuracy: 0.5147\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3648 - categorical_accuracy: 0.7026 - val_loss: 1.7113 - val_categorical_accuracy: 0.5305\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.3535 - categorical_accuracy: 0.6993 - val_loss: 1.7495 - val_categorical_accuracy: 0.5214\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.3166 - categorical_accuracy: 0.7220 - val_loss: 1.7072 - val_categorical_accuracy: 0.5169\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3264 - categorical_accuracy: 0.7173 - val_loss: 1.7067 - val_categorical_accuracy: 0.5372\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3032 - categorical_accuracy: 0.7281 - val_loss: 1.7195 - val_categorical_accuracy: 0.5260\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.3038 - categorical_accuracy: 0.7234 - val_loss: 1.7231 - val_categorical_accuracy: 0.5350\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2761 - categorical_accuracy: 0.7258 - val_loss: 1.7123 - val_categorical_accuracy: 0.5485\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2731 - categorical_accuracy: 0.7395 - val_loss: 1.7397 - val_categorical_accuracy: 0.5418\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2755 - categorical_accuracy: 0.7333 - val_loss: 1.6992 - val_categorical_accuracy: 0.5395\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2677 - categorical_accuracy: 0.7281 - val_loss: 1.7297 - val_categorical_accuracy: 0.5282\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.2516 - categorical_accuracy: 0.7485 - val_loss: 1.7053 - val_categorical_accuracy: 0.5530\n",
      "2115/2115 [==============================] - 1s 471us/sample - loss: 1.0090 - categorical_accuracy: 0.8856\n",
      "443/443 [==============================] - 0s 480us/sample - loss: 1.7053 - categorical_accuracy: 0.5530\n",
      "train categorical_accuracy: 88.558%\n",
      "test categorical_accuracy: 55.305%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 22, 741, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_49 (ELU)                 (None, 22, 741, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 22, 741, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 22, 185, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 22, 185, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 22, 176, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_50 (ELU)                 (None, 22, 176, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 22, 176, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 22, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 22, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 22, 35, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_51 (ELU)                 (None, 22, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 22, 35, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 22, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 22, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 2, 8, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_52 (ELU)                 (None, 2, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 2, 8, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 200,356\n",
      "Trainable params: 200,220\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================800===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 3.4197 - categorical_accuracy: 0.2686 - val_loss: 2.8811 - val_categorical_accuracy: 0.2664\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.8011 - categorical_accuracy: 0.2861 - val_loss: 2.6067 - val_categorical_accuracy: 0.3047\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.5715 - categorical_accuracy: 0.3466 - val_loss: 2.3719 - val_categorical_accuracy: 0.4108\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.4182 - categorical_accuracy: 0.3754 - val_loss: 2.2543 - val_categorical_accuracy: 0.4312\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.2610 - categorical_accuracy: 0.4095 - val_loss: 2.1896 - val_categorical_accuracy: 0.4176\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.1436 - categorical_accuracy: 0.4463 - val_loss: 2.0740 - val_categorical_accuracy: 0.4650\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 2.0563 - categorical_accuracy: 0.4761 - val_loss: 2.0321 - val_categorical_accuracy: 0.4560\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.9528 - categorical_accuracy: 0.4998 - val_loss: 1.9622 - val_categorical_accuracy: 0.4831\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8711 - categorical_accuracy: 0.5437 - val_loss: 1.9227 - val_categorical_accuracy: 0.5079\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8266 - categorical_accuracy: 0.5433 - val_loss: 1.8865 - val_categorical_accuracy: 0.4966\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.7858 - categorical_accuracy: 0.5598 - val_loss: 1.8592 - val_categorical_accuracy: 0.5034\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.7359 - categorical_accuracy: 0.5797 - val_loss: 1.8621 - val_categorical_accuracy: 0.5011\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.6748 - categorical_accuracy: 0.6033 - val_loss: 1.8204 - val_categorical_accuracy: 0.5102\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.6565 - categorical_accuracy: 0.6052 - val_loss: 1.7946 - val_categorical_accuracy: 0.5124\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.6140 - categorical_accuracy: 0.6170 - val_loss: 1.7997 - val_categorical_accuracy: 0.5237\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.6073 - categorical_accuracy: 0.6099 - val_loss: 1.7472 - val_categorical_accuracy: 0.5260\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.5571 - categorical_accuracy: 0.6364 - val_loss: 1.7480 - val_categorical_accuracy: 0.5282\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.5457 - categorical_accuracy: 0.6331 - val_loss: 1.7355 - val_categorical_accuracy: 0.5327\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4961 - categorical_accuracy: 0.6534 - val_loss: 1.7061 - val_categorical_accuracy: 0.5508\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5065 - categorical_accuracy: 0.6501 - val_loss: 1.7134 - val_categorical_accuracy: 0.5576\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4776 - categorical_accuracy: 0.6586 - val_loss: 1.6775 - val_categorical_accuracy: 0.5463\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4333 - categorical_accuracy: 0.6742 - val_loss: 1.6687 - val_categorical_accuracy: 0.5440\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4140 - categorical_accuracy: 0.6766 - val_loss: 1.6833 - val_categorical_accuracy: 0.5621\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4211 - categorical_accuracy: 0.6747 - val_loss: 1.6685 - val_categorical_accuracy: 0.5576\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3890 - categorical_accuracy: 0.6903 - val_loss: 1.6605 - val_categorical_accuracy: 0.5508\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3987 - categorical_accuracy: 0.6827 - val_loss: 1.6637 - val_categorical_accuracy: 0.5621\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3639 - categorical_accuracy: 0.6922 - val_loss: 1.7032 - val_categorical_accuracy: 0.5440\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3621 - categorical_accuracy: 0.6927 - val_loss: 1.6628 - val_categorical_accuracy: 0.5418\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3353 - categorical_accuracy: 0.7054 - val_loss: 1.6579 - val_categorical_accuracy: 0.5734\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3374 - categorical_accuracy: 0.7102 - val_loss: 1.6487 - val_categorical_accuracy: 0.5643\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2936 - categorical_accuracy: 0.7196 - val_loss: 1.6466 - val_categorical_accuracy: 0.5508\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2998 - categorical_accuracy: 0.7206 - val_loss: 1.6882 - val_categorical_accuracy: 0.5395\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3067 - categorical_accuracy: 0.7296 - val_loss: 1.6496 - val_categorical_accuracy: 0.5508\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2789 - categorical_accuracy: 0.7168 - val_loss: 1.6378 - val_categorical_accuracy: 0.5485\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2860 - categorical_accuracy: 0.7177 - val_loss: 1.6285 - val_categorical_accuracy: 0.5576\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2453 - categorical_accuracy: 0.7296 - val_loss: 1.6485 - val_categorical_accuracy: 0.5530\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2515 - categorical_accuracy: 0.7310 - val_loss: 1.6144 - val_categorical_accuracy: 0.5666\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2243 - categorical_accuracy: 0.7376 - val_loss: 1.6290 - val_categorical_accuracy: 0.5666\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2162 - categorical_accuracy: 0.7418 - val_loss: 1.6581 - val_categorical_accuracy: 0.5711\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2110 - categorical_accuracy: 0.7504 - val_loss: 1.6358 - val_categorical_accuracy: 0.5576\n",
      "2115/2115 [==============================] - 2s 867us/sample - loss: 0.9949 - categorical_accuracy: 0.8752\n",
      "443/443 [==============================] - 0s 907us/sample - loss: 1.6358 - categorical_accuracy: 0.5576\n",
      "train categorical_accuracy: 87.518%\n",
      "test categorical_accuracy: 55.756%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_53 (Conv2D)           (None, 22, 791, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_53 (ELU)                 (None, 22, 791, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 22, 791, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 22, 197, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 22, 197, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 22, 188, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_54 (ELU)                 (None, 22, 188, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 22, 188, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 22, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 22, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 22, 38, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_55 (ELU)                 (None, 22, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 22, 38, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 22, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 22, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 2, 9, 128)         172160    \n",
      "_________________________________________________________________\n",
      "elu_56 (ELU)                 (None, 2, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 2, 9, 128)         8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 200,356\n",
      "Trainable params: 200,220\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================850===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 10s 5ms/sample - loss: 3.4889 - categorical_accuracy: 0.2577 - val_loss: 2.8369 - val_categorical_accuracy: 0.2686\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 2.8341 - categorical_accuracy: 0.2374 - val_loss: 2.6430 - val_categorical_accuracy: 0.2190\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 2.6288 - categorical_accuracy: 0.2610 - val_loss: 2.4113 - val_categorical_accuracy: 0.3296\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 2.4392 - categorical_accuracy: 0.2809 - val_loss: 2.2625 - val_categorical_accuracy: 0.3725\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.2876 - categorical_accuracy: 0.3206 - val_loss: 2.1549 - val_categorical_accuracy: 0.3521\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.1846 - categorical_accuracy: 0.3598 - val_loss: 2.0763 - val_categorical_accuracy: 0.3792\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.0603 - categorical_accuracy: 0.3920 - val_loss: 1.9861 - val_categorical_accuracy: 0.4221\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.9678 - categorical_accuracy: 0.4336 - val_loss: 1.9278 - val_categorical_accuracy: 0.4379\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8710 - categorical_accuracy: 0.4615 - val_loss: 1.8720 - val_categorical_accuracy: 0.4515\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8009 - categorical_accuracy: 0.4950 - val_loss: 1.8192 - val_categorical_accuracy: 0.4989\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.7452 - categorical_accuracy: 0.5272 - val_loss: 1.8071 - val_categorical_accuracy: 0.4740\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.6894 - categorical_accuracy: 0.5541 - val_loss: 1.7638 - val_categorical_accuracy: 0.4763\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.6506 - categorical_accuracy: 0.5518 - val_loss: 1.7164 - val_categorical_accuracy: 0.4989\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.6115 - categorical_accuracy: 0.5787 - val_loss: 1.7233 - val_categorical_accuracy: 0.5011\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 5s 3ms/sample - loss: 1.5506 - categorical_accuracy: 0.5986 - val_loss: 1.7048 - val_categorical_accuracy: 0.5102\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5524 - categorical_accuracy: 0.5825 - val_loss: 1.6530 - val_categorical_accuracy: 0.5079\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5221 - categorical_accuracy: 0.6099 - val_loss: 1.6609 - val_categorical_accuracy: 0.5147\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4770 - categorical_accuracy: 0.6161 - val_loss: 1.6359 - val_categorical_accuracy: 0.5102\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4471 - categorical_accuracy: 0.6322 - val_loss: 1.6152 - val_categorical_accuracy: 0.5237\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4533 - categorical_accuracy: 0.6331 - val_loss: 1.6079 - val_categorical_accuracy: 0.5260\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4142 - categorical_accuracy: 0.6430 - val_loss: 1.5969 - val_categorical_accuracy: 0.5237\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3984 - categorical_accuracy: 0.6359 - val_loss: 1.5950 - val_categorical_accuracy: 0.5327\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3866 - categorical_accuracy: 0.6534 - val_loss: 1.5849 - val_categorical_accuracy: 0.5418\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3257 - categorical_accuracy: 0.6700 - val_loss: 1.6314 - val_categorical_accuracy: 0.5485\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3425 - categorical_accuracy: 0.6690 - val_loss: 1.5718 - val_categorical_accuracy: 0.5485\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3054 - categorical_accuracy: 0.6775 - val_loss: 1.5749 - val_categorical_accuracy: 0.5508\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2977 - categorical_accuracy: 0.6861 - val_loss: 1.5621 - val_categorical_accuracy: 0.5530\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2711 - categorical_accuracy: 0.7007 - val_loss: 1.5681 - val_categorical_accuracy: 0.5553\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2613 - categorical_accuracy: 0.6955 - val_loss: 1.5623 - val_categorical_accuracy: 0.5598\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2558 - categorical_accuracy: 0.7007 - val_loss: 1.5787 - val_categorical_accuracy: 0.5508\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2290 - categorical_accuracy: 0.7130 - val_loss: 1.5564 - val_categorical_accuracy: 0.5643\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2174 - categorical_accuracy: 0.7139 - val_loss: 1.5800 - val_categorical_accuracy: 0.5643\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2087 - categorical_accuracy: 0.7196 - val_loss: 1.5825 - val_categorical_accuracy: 0.5508\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.1996 - categorical_accuracy: 0.7220 - val_loss: 1.5409 - val_categorical_accuracy: 0.5643\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.1824 - categorical_accuracy: 0.7329 - val_loss: 1.5558 - val_categorical_accuracy: 0.5576\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.1644 - categorical_accuracy: 0.7371 - val_loss: 1.5394 - val_categorical_accuracy: 0.5666\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.1676 - categorical_accuracy: 0.7234 - val_loss: 1.5677 - val_categorical_accuracy: 0.5553\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.1562 - categorical_accuracy: 0.7262 - val_loss: 1.5543 - val_categorical_accuracy: 0.5643\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.1406 - categorical_accuracy: 0.7366 - val_loss: 1.5516 - val_categorical_accuracy: 0.5576\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.1259 - categorical_accuracy: 0.7470 - val_loss: 1.5343 - val_categorical_accuracy: 0.5801\n",
      "2115/2115 [==============================] - 2s 894us/sample - loss: 0.9121 - categorical_accuracy: 0.8813\n",
      "443/443 [==============================] - 0s 839us/sample - loss: 1.5343 - categorical_accuracy: 0.5801\n",
      "train categorical_accuracy: 88.132%\n",
      "test categorical_accuracy: 58.014%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 22, 841, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_57 (ELU)                 (None, 22, 841, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 22, 841, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 22, 210, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 22, 210, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 22, 201, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_58 (ELU)                 (None, 22, 201, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 22, 201, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 22, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 22, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 22, 41, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_59 (ELU)                 (None, 22, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 22, 41, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 22, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 22, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 2, 10, 128)        172160    \n",
      "_________________________________________________________________\n",
      "elu_60 (ELU)                 (None, 2, 10, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 2, 10, 128)        8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 200,356\n",
      "Trainable params: 200,220\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================900===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 11s 5ms/sample - loss: 3.4052 - categorical_accuracy: 0.2534 - val_loss: 2.9763 - val_categorical_accuracy: 0.2460\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 2.8525 - categorical_accuracy: 0.2728 - val_loss: 2.5910 - val_categorical_accuracy: 0.3521\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.6330 - categorical_accuracy: 0.3102 - val_loss: 2.4228 - val_categorical_accuracy: 0.3905\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.4372 - categorical_accuracy: 0.3527 - val_loss: 2.2920 - val_categorical_accuracy: 0.4199\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.2780 - categorical_accuracy: 0.4061 - val_loss: 2.2120 - val_categorical_accuracy: 0.4357\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.1591 - categorical_accuracy: 0.4496 - val_loss: 2.1193 - val_categorical_accuracy: 0.4470\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.0625 - categorical_accuracy: 0.4690 - val_loss: 2.0475 - val_categorical_accuracy: 0.4831\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.9673 - categorical_accuracy: 0.5050 - val_loss: 1.9859 - val_categorical_accuracy: 0.4921\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8923 - categorical_accuracy: 0.5310 - val_loss: 1.9597 - val_categorical_accuracy: 0.4650\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8576 - categorical_accuracy: 0.5499 - val_loss: 1.9025 - val_categorical_accuracy: 0.4921\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8196 - categorical_accuracy: 0.5565 - val_loss: 1.9198 - val_categorical_accuracy: 0.4786\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.7661 - categorical_accuracy: 0.5626 - val_loss: 1.8607 - val_categorical_accuracy: 0.4966\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.7288 - categorical_accuracy: 0.5768 - val_loss: 1.8375 - val_categorical_accuracy: 0.4921\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.6868 - categorical_accuracy: 0.5957 - val_loss: 1.8221 - val_categorical_accuracy: 0.5011\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.6473 - categorical_accuracy: 0.6090 - val_loss: 1.8330 - val_categorical_accuracy: 0.4876\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.6170 - categorical_accuracy: 0.6147 - val_loss: 1.7826 - val_categorical_accuracy: 0.5124\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5933 - categorical_accuracy: 0.6288 - val_loss: 1.7946 - val_categorical_accuracy: 0.5147\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5777 - categorical_accuracy: 0.6340 - val_loss: 1.7549 - val_categorical_accuracy: 0.5102\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5461 - categorical_accuracy: 0.6426 - val_loss: 1.7486 - val_categorical_accuracy: 0.5124\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5280 - categorical_accuracy: 0.6454 - val_loss: 1.7331 - val_categorical_accuracy: 0.5147\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5122 - categorical_accuracy: 0.6492 - val_loss: 1.7494 - val_categorical_accuracy: 0.4944\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4959 - categorical_accuracy: 0.6525 - val_loss: 1.7274 - val_categorical_accuracy: 0.5079\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4671 - categorical_accuracy: 0.6681 - val_loss: 1.7259 - val_categorical_accuracy: 0.5102\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4401 - categorical_accuracy: 0.6690 - val_loss: 1.7079 - val_categorical_accuracy: 0.5260\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4168 - categorical_accuracy: 0.6747 - val_loss: 1.6922 - val_categorical_accuracy: 0.5305\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.4201 - categorical_accuracy: 0.6719 - val_loss: 1.7409 - val_categorical_accuracy: 0.5124\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3898 - categorical_accuracy: 0.6856 - val_loss: 1.6901 - val_categorical_accuracy: 0.5327\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3849 - categorical_accuracy: 0.6875 - val_loss: 1.6753 - val_categorical_accuracy: 0.5372\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3768 - categorical_accuracy: 0.6908 - val_loss: 1.6634 - val_categorical_accuracy: 0.5463\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3643 - categorical_accuracy: 0.6865 - val_loss: 1.6640 - val_categorical_accuracy: 0.5440\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3609 - categorical_accuracy: 0.6922 - val_loss: 1.6774 - val_categorical_accuracy: 0.5372\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3156 - categorical_accuracy: 0.7111 - val_loss: 1.6817 - val_categorical_accuracy: 0.5418\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3138 - categorical_accuracy: 0.7173 - val_loss: 1.6617 - val_categorical_accuracy: 0.5508\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3268 - categorical_accuracy: 0.7007 - val_loss: 1.6602 - val_categorical_accuracy: 0.5395\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.3014 - categorical_accuracy: 0.7064 - val_loss: 1.6671 - val_categorical_accuracy: 0.5485\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2705 - categorical_accuracy: 0.7253 - val_loss: 1.6366 - val_categorical_accuracy: 0.5463\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2754 - categorical_accuracy: 0.7196 - val_loss: 1.6275 - val_categorical_accuracy: 0.5485\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2656 - categorical_accuracy: 0.7262 - val_loss: 1.6251 - val_categorical_accuracy: 0.5553\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2471 - categorical_accuracy: 0.7286 - val_loss: 1.6233 - val_categorical_accuracy: 0.5485\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.2508 - categorical_accuracy: 0.7338 - val_loss: 1.6445 - val_categorical_accuracy: 0.5327\n",
      "2115/2115 [==============================] - 2s 963us/sample - loss: 1.0396 - categorical_accuracy: 0.8553\n",
      "443/443 [==============================] - 0s 886us/sample - loss: 1.6445 - categorical_accuracy: 0.5327\n",
      "train categorical_accuracy: 85.532%\n",
      "test categorical_accuracy: 53.273%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 22, 891, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_61 (ELU)                 (None, 22, 891, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 22, 891, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 22, 222, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 22, 222, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 22, 213, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_62 (ELU)                 (None, 22, 213, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 22, 213, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 22, 53, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 22, 53, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 22, 44, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_63 (ELU)                 (None, 22, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 22, 44, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 22, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 22, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 2, 11, 128)        172160    \n",
      "_________________________________________________________________\n",
      "elu_64 (ELU)                 (None, 2, 11, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 2, 11, 128)        8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 200,356\n",
      "Trainable params: 200,220\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================950===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 11s 5ms/sample - loss: 3.4079 - categorical_accuracy: 0.2714 - val_loss: 2.9075 - val_categorical_accuracy: 0.2889\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 2.8419 - categorical_accuracy: 0.2775 - val_loss: 2.6390 - val_categorical_accuracy: 0.2596\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 2.6400 - categorical_accuracy: 0.3002 - val_loss: 2.4012 - val_categorical_accuracy: 0.3499\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 2.4524 - categorical_accuracy: 0.3310 - val_loss: 2.3001 - val_categorical_accuracy: 0.3928\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.2929 - categorical_accuracy: 0.3797 - val_loss: 2.1801 - val_categorical_accuracy: 0.4131\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.1658 - categorical_accuracy: 0.4095 - val_loss: 2.1014 - val_categorical_accuracy: 0.4357\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 2.0765 - categorical_accuracy: 0.4383 - val_loss: 2.0279 - val_categorical_accuracy: 0.4560\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.9780 - categorical_accuracy: 0.4823 - val_loss: 1.9629 - val_categorical_accuracy: 0.4808\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.8944 - categorical_accuracy: 0.5059 - val_loss: 1.9099 - val_categorical_accuracy: 0.4718\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.8352 - categorical_accuracy: 0.5333 - val_loss: 1.9073 - val_categorical_accuracy: 0.4853\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.7953 - categorical_accuracy: 0.5470 - val_loss: 1.8506 - val_categorical_accuracy: 0.4944\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.7376 - categorical_accuracy: 0.5688 - val_loss: 1.8267 - val_categorical_accuracy: 0.5124\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.7105 - categorical_accuracy: 0.5669 - val_loss: 1.8019 - val_categorical_accuracy: 0.5056\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.6579 - categorical_accuracy: 0.5967 - val_loss: 1.7722 - val_categorical_accuracy: 0.5282\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.6071 - categorical_accuracy: 0.6142 - val_loss: 1.7502 - val_categorical_accuracy: 0.5214\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.6075 - categorical_accuracy: 0.6194 - val_loss: 1.7531 - val_categorical_accuracy: 0.5169\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5693 - categorical_accuracy: 0.6208 - val_loss: 1.7184 - val_categorical_accuracy: 0.5350\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5249 - categorical_accuracy: 0.6392 - val_loss: 1.7129 - val_categorical_accuracy: 0.5282\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5135 - categorical_accuracy: 0.6402 - val_loss: 1.7063 - val_categorical_accuracy: 0.5440\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4935 - categorical_accuracy: 0.6421 - val_loss: 1.7039 - val_categorical_accuracy: 0.5395\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4652 - categorical_accuracy: 0.6440 - val_loss: 1.7201 - val_categorical_accuracy: 0.5485\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4427 - categorical_accuracy: 0.6591 - val_loss: 1.6988 - val_categorical_accuracy: 0.5440\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4372 - categorical_accuracy: 0.6657 - val_loss: 1.7024 - val_categorical_accuracy: 0.5327\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4053 - categorical_accuracy: 0.6799 - val_loss: 1.7039 - val_categorical_accuracy: 0.5372\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3951 - categorical_accuracy: 0.6870 - val_loss: 1.6761 - val_categorical_accuracy: 0.5418\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3826 - categorical_accuracy: 0.6851 - val_loss: 1.7286 - val_categorical_accuracy: 0.5440\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3634 - categorical_accuracy: 0.6941 - val_loss: 1.6603 - val_categorical_accuracy: 0.5485\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3422 - categorical_accuracy: 0.7012 - val_loss: 1.6824 - val_categorical_accuracy: 0.5418\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3291 - categorical_accuracy: 0.7083 - val_loss: 1.6860 - val_categorical_accuracy: 0.5395\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3304 - categorical_accuracy: 0.7102 - val_loss: 1.6606 - val_categorical_accuracy: 0.5372\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2800 - categorical_accuracy: 0.7272 - val_loss: 1.6642 - val_categorical_accuracy: 0.5530\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2960 - categorical_accuracy: 0.7069 - val_loss: 1.6841 - val_categorical_accuracy: 0.5418\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2952 - categorical_accuracy: 0.7069 - val_loss: 1.6661 - val_categorical_accuracy: 0.5395\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2635 - categorical_accuracy: 0.7376 - val_loss: 1.6580 - val_categorical_accuracy: 0.5463\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2452 - categorical_accuracy: 0.7248 - val_loss: 1.6745 - val_categorical_accuracy: 0.5553\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2362 - categorical_accuracy: 0.7385 - val_loss: 1.6623 - val_categorical_accuracy: 0.5372\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2363 - categorical_accuracy: 0.7376 - val_loss: 1.7191 - val_categorical_accuracy: 0.5372\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2273 - categorical_accuracy: 0.7300 - val_loss: 1.6788 - val_categorical_accuracy: 0.5350\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2112 - categorical_accuracy: 0.7485 - val_loss: 1.6910 - val_categorical_accuracy: 0.5124\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.1865 - categorical_accuracy: 0.7584 - val_loss: 1.6985 - val_categorical_accuracy: 0.5305\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 0.9684 - categorical_accuracy: 0.8846\n",
      "443/443 [==============================] - 0s 1ms/sample - loss: 1.6985 - categorical_accuracy: 0.5305\n",
      "train categorical_accuracy: 88.463%\n",
      "test categorical_accuracy: 53.047%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_65 (Conv2D)           (None, 22, 941, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_65 (ELU)                 (None, 22, 941, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 22, 941, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 22, 235, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 22, 235, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 22, 226, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_66 (ELU)                 (None, 22, 226, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 22, 226, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 22, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 22, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 22, 47, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_67 (ELU)                 (None, 22, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 22, 47, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 22, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 22, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 2, 11, 128)        172160    \n",
      "_________________________________________________________________\n",
      "elu_68 (ELU)                 (None, 2, 11, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 2, 11, 128)        8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 200,356\n",
      "Trainable params: 200,220\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================1000===================\n",
      "Train on 2115 samples, validate on 443 samples\n",
      "Epoch 1/40\n",
      "2115/2115 [==============================] - 11s 5ms/sample - loss: 3.6273 - categorical_accuracy: 0.2605 - val_loss: 2.9514 - val_categorical_accuracy: 0.2686\n",
      "Epoch 2/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 2.8947 - categorical_accuracy: 0.2733 - val_loss: 2.6191 - val_categorical_accuracy: 0.3070\n",
      "Epoch 3/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 2.6759 - categorical_accuracy: 0.2775 - val_loss: 2.4839 - val_categorical_accuracy: 0.3318\n",
      "Epoch 4/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 2.4881 - categorical_accuracy: 0.3314 - val_loss: 2.3376 - val_categorical_accuracy: 0.3634\n",
      "Epoch 5/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 2.3584 - categorical_accuracy: 0.3608 - val_loss: 2.2258 - val_categorical_accuracy: 0.3905\n",
      "Epoch 6/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 2.2287 - categorical_accuracy: 0.4000 - val_loss: 2.1476 - val_categorical_accuracy: 0.3973\n",
      "Epoch 7/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 2.1373 - categorical_accuracy: 0.4255 - val_loss: 2.0798 - val_categorical_accuracy: 0.4582\n",
      "Epoch 8/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 2.0380 - categorical_accuracy: 0.4605 - val_loss: 2.0248 - val_categorical_accuracy: 0.4650\n",
      "Epoch 9/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.9753 - categorical_accuracy: 0.4785 - val_loss: 1.9699 - val_categorical_accuracy: 0.4831\n",
      "Epoch 10/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.8898 - categorical_accuracy: 0.5106 - val_loss: 1.9392 - val_categorical_accuracy: 0.4831\n",
      "Epoch 11/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.8499 - categorical_accuracy: 0.5348 - val_loss: 1.9058 - val_categorical_accuracy: 0.4989\n",
      "Epoch 12/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.7921 - categorical_accuracy: 0.5546 - val_loss: 1.8719 - val_categorical_accuracy: 0.5011\n",
      "Epoch 13/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.7549 - categorical_accuracy: 0.5660 - val_loss: 1.8473 - val_categorical_accuracy: 0.4989\n",
      "Epoch 14/40\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.7094 - categorical_accuracy: 0.5768 - val_loss: 1.8258 - val_categorical_accuracy: 0.5237\n",
      "Epoch 15/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.6736 - categorical_accuracy: 0.6009 - val_loss: 1.8064 - val_categorical_accuracy: 0.5327\n",
      "Epoch 16/40\n",
      "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.6332 - categorical_accuracy: 0.5943 - val_loss: 1.8168 - val_categorical_accuracy: 0.5192\n",
      "Epoch 17/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.6201 - categorical_accuracy: 0.6189 - val_loss: 1.8077 - val_categorical_accuracy: 0.5305\n",
      "Epoch 18/40\n",
      "2115/2115 [==============================] - 6s 3ms/sample - loss: 1.5607 - categorical_accuracy: 0.6383 - val_loss: 1.7484 - val_categorical_accuracy: 0.5260\n",
      "Epoch 19/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5549 - categorical_accuracy: 0.6397 - val_loss: 1.7585 - val_categorical_accuracy: 0.5169\n",
      "Epoch 20/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.5235 - categorical_accuracy: 0.6407 - val_loss: 1.7497 - val_categorical_accuracy: 0.5372\n",
      "Epoch 21/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4834 - categorical_accuracy: 0.6586 - val_loss: 1.7322 - val_categorical_accuracy: 0.5440\n",
      "Epoch 22/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4704 - categorical_accuracy: 0.6752 - val_loss: 1.7441 - val_categorical_accuracy: 0.5598\n",
      "Epoch 23/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4402 - categorical_accuracy: 0.6823 - val_loss: 1.7272 - val_categorical_accuracy: 0.5576\n",
      "Epoch 24/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4253 - categorical_accuracy: 0.6790 - val_loss: 1.7122 - val_categorical_accuracy: 0.5598\n",
      "Epoch 25/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4196 - categorical_accuracy: 0.6842 - val_loss: 1.7065 - val_categorical_accuracy: 0.5485\n",
      "Epoch 26/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.4019 - categorical_accuracy: 0.6884 - val_loss: 1.7136 - val_categorical_accuracy: 0.5530\n",
      "Epoch 27/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3712 - categorical_accuracy: 0.6955 - val_loss: 1.6973 - val_categorical_accuracy: 0.5711\n",
      "Epoch 28/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3490 - categorical_accuracy: 0.7045 - val_loss: 1.7099 - val_categorical_accuracy: 0.5598\n",
      "Epoch 29/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3427 - categorical_accuracy: 0.7040 - val_loss: 1.7074 - val_categorical_accuracy: 0.5779\n",
      "Epoch 30/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3470 - categorical_accuracy: 0.7002 - val_loss: 1.6812 - val_categorical_accuracy: 0.5666\n",
      "Epoch 31/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3325 - categorical_accuracy: 0.7106 - val_loss: 1.6809 - val_categorical_accuracy: 0.5598\n",
      "Epoch 32/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.3201 - categorical_accuracy: 0.7191 - val_loss: 1.6967 - val_categorical_accuracy: 0.5711\n",
      "Epoch 33/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2925 - categorical_accuracy: 0.7286 - val_loss: 1.6765 - val_categorical_accuracy: 0.5734\n",
      "Epoch 34/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2893 - categorical_accuracy: 0.7258 - val_loss: 1.6946 - val_categorical_accuracy: 0.5463\n",
      "Epoch 35/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2833 - categorical_accuracy: 0.7201 - val_loss: 1.6993 - val_categorical_accuracy: 0.5530\n",
      "Epoch 36/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2516 - categorical_accuracy: 0.7447 - val_loss: 1.6898 - val_categorical_accuracy: 0.5530\n",
      "Epoch 37/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2598 - categorical_accuracy: 0.7461 - val_loss: 1.6787 - val_categorical_accuracy: 0.5688\n",
      "Epoch 38/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2496 - categorical_accuracy: 0.7385 - val_loss: 1.6796 - val_categorical_accuracy: 0.5643\n",
      "Epoch 39/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2310 - categorical_accuracy: 0.7518 - val_loss: 1.6919 - val_categorical_accuracy: 0.5576\n",
      "Epoch 40/40\n",
      "2115/2115 [==============================] - 7s 3ms/sample - loss: 1.2266 - categorical_accuracy: 0.7371 - val_loss: 1.6835 - val_categorical_accuracy: 0.5824\n",
      "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.0008 - categorical_accuracy: 0.8832\n",
      "443/443 [==============================] - 0s 1ms/sample - loss: 1.6835 - categorical_accuracy: 0.5824\n",
      "train categorical_accuracy: 88.322%\n",
      "test categorical_accuracy: 58.239%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 22, 991, 16)       176       \n",
      "_________________________________________________________________\n",
      "elu_69 (ELU)                 (None, 22, 991, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 22, 991, 16)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 22, 247, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 22, 247, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 22, 238, 32)       5152      \n",
      "_________________________________________________________________\n",
      "elu_70 (ELU)                 (None, 22, 238, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 22, 238, 32)       88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 22, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 22, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 22, 50, 64)        20544     \n",
      "_________________________________________________________________\n",
      "elu_71 (ELU)                 (None, 22, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 22, 50, 64)        88        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 22, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 22, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 2, 12, 128)        172160    \n",
      "_________________________________________________________________\n",
      "elu_72 (ELU)                 (None, 2, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 2, 12, 128)        8         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 2, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 2, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 3076      \n",
      "=================================================================\n",
      "Total params: 201,380\n",
      "Trainable params: 201,244\n",
      "Non-trainable params: 136\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train accuracies: \n",
      "[0.7527187, 0.8534279, 0.93758863, 0.9839243, 0.9895981, 0.93049645, 0.9853428, 0.83356977, 0.81985813, 0.8004728, 0.8255319, 0.8307329, 0.8283688, 0.88557917, 0.8751773, 0.8813239, 0.85531914, 0.88463354, 0.8832151]\n",
      "Test accuracies: \n",
      "[0.45598194, 0.496614, 0.4650113, 0.44469526, 0.50564337, 0.54401803, 0.51241535, 0.5688487, 0.5891648, 0.5598194, 0.60722345, 0.5846501, 0.5643341, 0.5530474, 0.55756205, 0.58013546, 0.53273135, 0.53047407, 0.58239275]\n",
      "The best accuracy is 0.607.\n",
      "The corresponding time period is 600.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCWEhhBBCJRLCQgghhEokhIUQQgiV/D8H8aEueZ+m8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(100, 1001, 50):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])\n",
    "\n",
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "max_idx = np.argmax(test_scores)\n",
    "print(\"The best accuracy is %.3f.\" %max(test_scores))\n",
    "print(\"The corresponding time period is %d.\" %(100 + 50 * max_idx))\n",
    "\n",
    "# plot\n",
    "plt.plot(range(100, 1001, 50), train_scores, label='train accuracies')\n",
    "plt.plot(range(100, 1001, 50), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
