{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the k-nearest neighbors workbook for ECE 239AS Assignment #2\n",
    "\n",
    "Please follow the notebook linearly to implement k-nearest neighbors.\n",
    "\n",
    "Please print out the workbook entirely when completed.\n",
    "\n",
    "We thank Serena Yeung & Justin Johnson for permission to use code written for the CS 231n class (cs231n.stanford.edu).  These are the functions in the cs231n folders and code in the jupyer notebook to preprocess and show the images.  The classifiers used are based off of code prepared for CS 231n as well.\n",
    "\n",
    "The goal of this workbook is to give you experience with the data, training and evaluating a simple classifier, k-fold cross validation, and as a Python refresher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the appropriate libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for doing most of our calculations\n",
    "import matplotlib.pyplot as plt# for plotting\n",
    "from cs231n.data_utils import load_CIFAR10 # function to load the CIFAR-10 dataset.\n",
    "\n",
    "# Load matplotlib images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# These are important for reloading any code you write in external .py files.\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the CIFAR-10 data\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbors\n",
    "\n",
    "In the following cells, you will build a KNN classifier and choose hyperparameters via k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNN class\n",
    "\n",
    "from nndl import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare an instance of the knn class.\n",
    "knn = KNN()\n",
    "\n",
    "# Train the classifier.\n",
    "#   We have implemented the training of the KNN classifier.\n",
    "#   Look at the train function in the KNN class to see what this does.\n",
    "knn.train(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "(1) Describe what is going on in the function knn.train().\n",
    "\n",
    "(2) What are the pros and cons of this training step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "(1) You fill this in.\n",
    "\n",
    "(2) You fill this in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN prediction\n",
    "\n",
    "In the following sections, you will implement the functions to calculate the distances of test points to training points, and from this information, predict the class of the KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function compute_distances() in the KNN class.\n",
    "# Do not worry about the input 'norm' for now; use the default definition of the norm\n",
    "#   in the code, which is the 2-norm.\n",
    "# You should only have to fill out the clearly marked sections.\n",
    "\n",
    "import time\n",
    "time_start =time.time()\n",
    "\n",
    "dists_L2 = knn.compute_distances(X=X_test)\n",
    "\n",
    "print('Time to run code: {}'.format(time.time()-time_start))\n",
    "print('Frobenius norm of L2 distances: {}'.format(np.linalg.norm(dists_L2, 'fro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Really slow code\n",
    "\n",
    "Note: \n",
    "This probably took a while. This is because we use two for loops.  We could increase the speed via vectorization, removing the for loops.\n",
    "\n",
    "If you implemented this correctly, evaluating np.linalg.norm(dists_L2, 'fro') should return: ~7906696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN vectorization\n",
    "\n",
    "The above code took far too long to run.  If we wanted to optimize hyperparameters, it would be time-expensive.  Thus, we will speed up the code by vectorizing it, removing the for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function compute_L2_distances_vectorized() in the KNN class.\n",
    "# In this function, you ought to achieve the same L2 distance but WITHOUT any for loops.\n",
    "# Note, this is SPECIFIC for the L2 norm.\n",
    "\n",
    "time_start =time.time()\n",
    "dists_L2_vectorized = knn.compute_L2_distances_vectorized(X=X_test)\n",
    "print('Time to run code: {}'.format(time.time()-time_start))\n",
    "print('Difference in L2 distances between your KNN implementations (should be 0): {}'.format(np.linalg.norm(dists_L2 - dists_L2_vectorized, 'fro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speedup\n",
    "\n",
    "Depending on your computer speed, you should see a 10-100x speed up from vectorization.  On our computer, the vectorized form took 0.36 seconds while the naive implementation took 38.3 seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the prediction\n",
    "\n",
    "Now that we have functions to calculate the distances from a test point to given training points, we now implement the function that will predict the test point labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function predict_labels in the KNN class.\n",
    "# Calculate the training error (num_incorrect / total_samples) \n",
    "#   from running knn.predict_labels with k=1\n",
    "\n",
    "error = 1\n",
    "\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#   Calculate the error rate by calling predict_labels on the test \n",
    "#   data with k = 1.  Store the error rate in the variable error.\n",
    "# ================================================================ #\n",
    "pass\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented this correctly, the error should be: 0.726.\n",
    "\n",
    "This means that the k-nearest neighbors classifier is right 27.4% of the time, which is not great, considering that chance levels are 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing KNN hyperparameters\n",
    "\n",
    "In this section, we'll take the KNN classifier that you have constructed and perform cross-validation to choose a best value of $k$, as well as a best choice of norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and validation folds\n",
    "\n",
    "First, we will create the training and validation folds for use in k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset folds for cross-valdiation.\n",
    "num_folds = 5\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds =  []\n",
    "\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#   Split the training data into num_folds (i.e., 5) folds.\n",
    "#   X_train_folds is a list, where X_train_folds[i] contains the \n",
    "#      data points in fold i.\n",
    "#   y_train_folds is also a list, where y_train_folds[i] contains\n",
    "#      the corresponding labels for the data in X_train_folds[i]\n",
    "# ================================================================ #\n",
    "pass\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the number of nearest neighbors hyperparameter.\n",
    "\n",
    "In this section, we select different numbers of nearest neighbors and assess which one has the lowest k-fold cross validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start =time.time()\n",
    "\n",
    "ks = [1, 2, 3, 5, 7, 10, 15, 20, 25, 30]\n",
    "\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#   Calculate the cross-validation error for each k in ks, testing\n",
    "#   the trained model on each of the 5 folds.  Average these errors\n",
    "#   together and make a plot of k vs. cross-validation error. Since \n",
    "#   we are assuming L2 distance here, please use the vectorized code!\n",
    "#   Otherwise, you might be waiting a long time.\n",
    "# ================================================================ #\n",
    "\n",
    "pass\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n",
    "print('Computation time: %.2f'%(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "(1) What value of $k$ is best amongst the tested $k$'s?\n",
    "\n",
    "(2) What is the cross-validation error for this value of $k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers:\n",
    "\n",
    "(1) You fill this in.\n",
    "\n",
    "(2) You fill this in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the norm\n",
    "\n",
    "Next, we test three different norms (the 1, 2, and infinity norms) and see which distance metric results in the best cross-validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_start =time.time()\n",
    "\n",
    "L1_norm = lambda x: np.linalg.norm(x, ord=1)\n",
    "L2_norm = lambda x: np.linalg.norm(x, ord=2)\n",
    "Linf_norm = lambda x: np.linalg.norm(x, ord= np.inf)\n",
    "norms = [L1_norm, L2_norm, Linf_norm]\n",
    "\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#   Calculate the cross-validation error for each norm in norms, testing\n",
    "#   the trained model on each of the 5 folds.  Average these errors\n",
    "#   together and make a plot of the norm used vs the cross-validation error\n",
    "#   Use the best cross-validation k from the previous part.  \n",
    "#\n",
    "#   Feel free to use the compute_distances function.  We're testing just\n",
    "#   three norms, but be advised that this could still take some time.\n",
    "#   You're welcome to write a vectorized form of the L1- and Linf- norms\n",
    "#   to speed this up, but it is not necessary.\n",
    "# ================================================================ #\n",
    "\n",
    "pass\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "print('Computation time: %.2f'%(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "(1) What norm has the best cross-validation error?\n",
    "\n",
    "(2) What is the cross-validation error for your given norm and k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers: \n",
    "\n",
    "(1) You fill this in.\n",
    "\n",
    "(2) You fill this in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model on the testing dataset.\n",
    "\n",
    "Now, given the optimal $k$ and norm you found in earlier parts, evaluate the testing error of the k-nearest neighbors model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 1\n",
    "\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#   Evaluate the testing error of the k-nearest neighbors classifier\n",
    "#   for your optimal hyperparameters found by 5-fold cross-validation.\n",
    "# ================================================================ #\n",
    "\n",
    "pass\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n",
    "print('Error rate achieved: {}'.format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "How much did your error improve by cross-validation over naively choosing $k=1$ and using the L2-norm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "You fill this in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
